{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-02T15:28:55.226533Z",
     "start_time": "2024-08-02T15:28:51.938353Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cell_division.nets.transfer_learning import CNN\n",
    "from auxiliary.data.dataset_cell import CellDataset\n",
    "from auxiliary import values as v\n",
    "from auxiliary.utils.colors import bcolors as c\n",
    "\n",
    "# from focal_loss import SparseCategoricalFocalLoss\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from cell_division.nets.custom_layers import w_cel_loss, focal_loss\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# GPU config\n",
    "from auxiliary.utils.timer import LoadingBar\n",
    "from auxiliary.gpu.gpu_tf import (\n",
    "    increase_gpu_memory, \n",
    "    set_gpu_allocator, \n",
    "    clear_session\n",
    ")\n",
    "\n",
    "increase_gpu_memory()\n",
    "set_gpu_allocator()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:28:55.232422Z",
     "start_time": "2024-08-02T15:28:55.228619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = v.data_path + 'CellDivision/images/'\n",
    "label_train_dir = v.data_path + 'CellDivision/train.csv'\n",
    "label_test_dir = v.data_path + 'CellDivision/test.csv'\n",
    "label_val_dir = v.data_path + 'CellDivision/val.csv'\n",
    "\n",
    "INPUT_SHAPE = (50, 50, 3)\n",
    "BATCH_SIZE = 64"
   ],
   "id": "72671286f4e09b93",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dataset (Generators)\n",
    "\n",
    "Generatos do not load directly the images into memory, but they load the images on the fly. This is useful when the dataset is too large to fit into memory."
   ],
   "id": "6a22a8984306870e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:28:55.264682Z",
     "start_time": "2024-08-02T15:28:55.233620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_train_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "val_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_val_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")"
   ],
   "id": "a54e19ea8c8c2bc9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transfer Learning ",
   "id": "bd19c08a9ae85271"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:28:55.269446Z",
     "start_time": "2024-08-02T15:28:55.265823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)): \n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)"
   ],
   "id": "3cfdc36a7c36ec3f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:28:55.274218Z",
     "start_time": "2024-08-02T15:28:55.271112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_models = {\n",
    "    'DenseNet121': tf.keras.applications.DenseNet121,\n",
    "    'EfficientNetV2L': tf.keras.applications.EfficientNetV2L,\n",
    "    'EfficientNetV2M': tf.keras.applications.EfficientNetV2M,\n",
    "    'VGG16': tf.keras.applications.VGG16,\n",
    "    'ResNet50': tf.keras.applications.ResNet50,\n",
    "    'InceptionV3': tf.keras.applications.InceptionV3,\n",
    "    'MobileNetV2': tf.keras.applications.MobileNetV2,\n",
    "    'NASNetMobile': tf.keras.applications.NASNetMobile,\n",
    "}\n"
   ],
   "id": "199d42b8fb6d8443",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T15:28:55.278055Z",
     "start_time": "2024-08-02T15:28:55.275288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'base_model': list(base_models.keys()),\n",
    "    'lr': [1e-3, 1e-2],\n",
    "    'fine_tune': [True, False],\n",
    "    'loss': [focal_loss(), w_cel_loss()],\n",
    "    'top': ['CAM', 'Standard'],\n",
    "    # 'class_weight': [None, 'balanced']\n",
    "}"
   ],
   "id": "49cc59a243f56557",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-02T15:28:55.279274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorboard.errors import InvalidArgumentError\n",
    "\n",
    "bar = LoadingBar(\n",
    "    len(param_grid['base_model']) * len(param_grid['lr']) * len(param_grid['fine_tune']) * len(param_grid['loss']) * len(param_grid['top'])\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for base_model in param_grid['base_model']:\n",
    "    for lr in param_grid['lr']:\n",
    "        for fine_tune in param_grid['fine_tune']:\n",
    "            for loss in param_grid['loss']:\n",
    "                for top in param_grid['top']:\n",
    "                    print(f'{c.OKGREEN}Model: {base_model} - LR: {lr} - Fine Tune: {fine_tune} - Loss: {loss} - Top: {top}{c.ENDC}')\n",
    "                    \n",
    "                    try:\n",
    "                        model = CNN(\n",
    "                            base=base_models[base_model],\n",
    "                            n_classes=3,\n",
    "                            input_shape=INPUT_SHAPE,\n",
    "                            fine_tune=fine_tune\n",
    "                        )\n",
    "                        model.build_top(activation='softmax', b_type=top)\n",
    "                        model.compile(lr=lr, loss=loss)\n",
    "                        model.fit(\n",
    "                            train_generator,\n",
    "                            val_generator,\n",
    "                            epochs=100,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            save=False,\n",
    "                            verbose=1\n",
    "                        )\n",
    "    \n",
    "                        results[\n",
    "                            str((base_model, lr, fine_tune, loss.__name__, top))\n",
    "                        ] = model.model.history.history\n",
    "                    except Exception as e:\n",
    "                        print(f'{c.FAIL}Error: {e}{c.ENDC}')\n",
    "                        results[(base_model, lr, fine_tune, loss, top)] = None\n",
    "\n",
    "                    clear_session()\n",
    "                    bar.update()\n",
    "                    \n",
    "    with open(f'../cell_division/results/{base_model}.json', 'w') as f:\n",
    "        json.dump(results, f, cls=NumpyEncoder)\n",
    "    results = {}\n",
    "\n",
    "bar.end()"
   ],
   "id": "52c645a63e00890e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: True - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7758f4a84550> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
