{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cell_division.nets.transfer_learning import CNN\n",
    "from auxiliary.data.dataset_cell import CellDataset\n",
    "from auxiliary import values as v\n",
    "from auxiliary.utils.colors import bcolors as c\n",
    "\n",
    "# from focal_loss import SparseCategoricalFocalLoss\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from cell_division.nets.custom_layers import (\n",
    "    w_cel_loss, \n",
    "    focal_loss,\n",
    "    ExtendedLSEPooling,\n",
    "    extended_w_cel_loss\n",
    ")\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# GPU config\n",
    "from auxiliary.utils.timer import LoadingBar\n",
    "from auxiliary.gpu.gpu_tf import (\n",
    "    increase_gpu_memory, \n",
    "    set_gpu_allocator, \n",
    "    clear_session\n",
    ")\n",
    "\n",
    "increase_gpu_memory()\n",
    "set_gpu_allocator()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T13:46:09.084707Z",
     "start_time": "2024-08-05T13:46:09.081410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = v.data_path + 'CellDivision/images/'\n",
    "label_train_dir = v.data_path + 'CellDivision/train.csv'\n",
    "label_test_dir = v.data_path + 'CellDivision/test.csv'\n",
    "label_val_dir = v.data_path + 'CellDivision/val.csv'\n",
    "\n",
    "INPUT_SHAPE = (50, 50, 3)\n",
    "BATCH_SIZE = 8"
   ],
   "id": "72671286f4e09b93",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dataset (Generators)\n",
    "\n",
    "Generatos do not load directly the images into memory, but they load the images on the fly. This is useful when the dataset is too large to fit into memory."
   ],
   "id": "6a22a8984306870e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T13:46:09.115313Z",
     "start_time": "2024-08-05T13:46:09.086227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_train_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "val_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_val_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")"
   ],
   "id": "a54e19ea8c8c2bc9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transfer Learning ",
   "id": "bd19c08a9ae85271"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T13:46:09.120430Z",
     "start_time": "2024-08-05T13:46:09.116458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)): \n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)"
   ],
   "id": "3cfdc36a7c36ec3f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T13:46:09.127078Z",
     "start_time": "2024-08-05T13:46:09.122937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_models = {\n",
    "    'DenseNet121': tf.keras.applications.DenseNet121,\n",
    "    'EfficientNetV2L': tf.keras.applications.EfficientNetV2L,\n",
    "    'EfficientNetV2M': tf.keras.applications.EfficientNetV2M,\n",
    "    'VGG16': tf.keras.applications.VGG16,\n",
    "    'ResNet50': tf.keras.applications.ResNet50,\n",
    "    'InceptionV3': tf.keras.applications.InceptionV3,\n",
    "    'MobileNetV2': tf.keras.applications.MobileNetV2,\n",
    "    'NASNetMobile': tf.keras.applications.NASNetMobile,\n",
    "}\n"
   ],
   "id": "199d42b8fb6d8443",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T13:46:09.132477Z",
     "start_time": "2024-08-05T13:46:09.128493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'base_model': list(base_models.keys()),\n",
    "    'lr': [1e-3, 1e-2],\n",
    "    # 'fine_tune': [True, False],\n",
    "    'loss': [focal_loss(), w_cel_loss()],\n",
    "    'top': ['CAM', 'Standard'],\n",
    "    # 'class_weight': [None, 'balanced']\n",
    "}"
   ],
   "id": "49cc59a243f56557",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-05T13:46:09.133570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bar = LoadingBar(\n",
    "    len(param_grid['base_model']) * len(param_grid['lr']) * len(param_grid['loss']) * len(param_grid['top'])\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for base_model in param_grid['base_model']:\n",
    "    for lr in param_grid['lr']:\n",
    "        # for fine_tune in param_grid['fine_tune']:\n",
    "        for loss in param_grid['loss']:\n",
    "            for top in param_grid['top']:\n",
    "                print(f'\\n{c.OKGREEN}Model: {base_model} - LR: {lr} - Loss: {loss} - Top: {top}{c.ENDC}')\n",
    "                \n",
    "                try:\n",
    "                    model = CNN(\n",
    "                        base=base_models[base_model],\n",
    "                        n_classes=3,\n",
    "                        input_shape=INPUT_SHAPE\n",
    "                    )\n",
    "                    model.build_top(activation='softmax', b_type=top)\n",
    "                    model.compile(lr=lr, loss=loss)\n",
    "                    model.fit(\n",
    "                        train_generator,\n",
    "                        val_generator,\n",
    "                        epochs=100,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        save=False,\n",
    "                        verbose=1\n",
    "                    )\n",
    "\n",
    "                    results[\n",
    "                        str((base_model, lr, loss.__name__, top))\n",
    "                    ] = model.model.history.history\n",
    "                except Exception as e:\n",
    "                    print(f'{c.FAIL}Error:{c.ENDC} {e}')\n",
    "                    results[str((base_model, lr, loss.__name__, top))] = None\n",
    "\n",
    "                clear_session()\n",
    "                bar.update()\n",
    "                    \n",
    "    with open(f'../cell_division/results/{base_model}.json', 'w') as f:\n",
    "        json.dump(results, f, cls=NumpyEncoder)\n",
    "    results = {}\n",
    "\n",
    "bar.end()"
   ],
   "id": "52c645a63e00890e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mModel: DenseNet121 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 20s 149ms/step - loss: 0.0700 - auc: 0.7236 - val_loss: 0.0560 - val_auc: 0.7749 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0459 - auc: 0.8453 - val_loss: 0.0513 - val_auc: 0.8109 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0390 - auc: 0.8951 - val_loss: 0.0469 - val_auc: 0.8439 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0359 - auc: 0.9164 - val_loss: 0.0540 - val_auc: 0.7644 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0320 - auc: 0.9340 - val_loss: 0.0602 - val_auc: 0.8168 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0281 - auc: 0.9523 - val_loss: 0.0628 - val_auc: 0.8422 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0236 - auc: 0.9676\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.0236 - auc: 0.9676 - val_loss: 0.0551 - val_auc: 0.8518 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 12s 125ms/step - loss: 0.0177 - auc: 0.9834 - val_loss: 0.0467 - val_auc: 0.8743 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.0153 - auc: 0.9906 - val_loss: 0.0465 - val_auc: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0149 - auc: 0.9911\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.0149 - auc: 0.9911 - val_loss: 0.0464 - val_auc: 0.8813 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 0.0140 - auc: 0.9927 - val_loss: 0.0469 - val_auc: 0.8814 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.0139 - auc: 0.9926 - val_loss: 0.0468 - val_auc: 0.8816 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0139 - auc: 0.9927\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.0139 - auc: 0.9927 - val_loss: 0.0469 - val_auc: 0.8815 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0137 - auc: 0.9930 - val_loss: 0.0470 - val_auc: 0.8813 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0137 - auc: 0.9930 - val_loss: 0.0470 - val_auc: 0.8814 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0137 - auc: 0.9930\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0137 - auc: 0.9930 - val_loss: 0.0470 - val_auc: 0.8815 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0137 - auc: 0.9930Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.0137 - auc: 0.9930 - val_loss: 0.0470 - val_auc: 0.8815 - lr: 1.0000e-07\n",
      "Epoch 17: early stopping\n",
      "[                                                  ] 1.56%\u001B[92mModel: DenseNet121 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 18s 136ms/step - loss: 0.2979 - auc: 0.6195 - val_loss: 0.1462 - val_auc: 0.7382 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1710 - auc: 0.7271 - val_loss: 0.1375 - val_auc: 0.6932 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1465 - auc: 0.7636 - val_loss: 0.1117 - val_auc: 0.7466 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1274 - auc: 0.7983 - val_loss: 0.0878 - val_auc: 0.8062 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1165 - auc: 0.8044\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1165 - auc: 0.8044 - val_loss: 0.0946 - val_auc: 0.7726 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0905 - auc: 0.8397 - val_loss: 0.0734 - val_auc: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0879 - auc: 0.8429 - val_loss: 0.0741 - val_auc: 0.7991 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0799 - auc: 0.8490\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0799 - auc: 0.8490 - val_loss: 0.0724 - val_auc: 0.8050 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0733 - auc: 0.8697 - val_loss: 0.0714 - val_auc: 0.8083 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.0731 - auc: 0.8664 - val_loss: 0.0719 - val_auc: 0.8093 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0744 - auc: 0.8539\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0744 - auc: 0.8539 - val_loss: 0.0718 - val_auc: 0.8087 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0789 - auc: 0.8610 - val_loss: 0.0712 - val_auc: 0.8082 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0685 - auc: 0.8704 - val_loss: 0.0720 - val_auc: 0.8070 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0719 - auc: 0.8667\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0719 - auc: 0.8667 - val_loss: 0.0726 - val_auc: 0.8074 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0772 - auc: 0.8560Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0772 - auc: 0.8560 - val_loss: 0.0719 - val_auc: 0.8081 - lr: 1.0000e-07\n",
      "Epoch 15: early stopping\n",
      "[=                                                 ] 3.12%\u001B[92mModel: DenseNet121 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 18s 133ms/step - loss: 1.0108 - auc: 0.7002 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[==                                                ] 4.69%\u001B[92mModel: DenseNet121 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 19s 143ms/step - loss: 1.0741 - auc: 0.6550 - val_loss: 1.0544 - val_auc: 0.6625 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0100 - auc: 0.7435 - val_loss: 1.0385 - val_auc: 0.6930 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.9916 - auc: 0.7702 - val_loss: 0.9910 - val_auc: 0.7699 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9734 - auc: 0.7976\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9734 - auc: 0.7976 - val_loss: 1.0223 - val_auc: 0.7246 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9415 - auc: 0.8400 - val_loss: 0.9948 - val_auc: 0.7879 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9302 - auc: 0.8598 - val_loss: 0.9762 - val_auc: 0.8043 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9211 - auc: 0.8733\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.9211 - auc: 0.8733 - val_loss: 0.9746 - val_auc: 0.8113 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.9165 - auc: 0.8751 - val_loss: 0.9744 - val_auc: 0.8161 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9173 - auc: 0.8721 - val_loss: 0.9740 - val_auc: 0.8145 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9161 - auc: 0.8733\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9161 - auc: 0.8733 - val_loss: 0.9749 - val_auc: 0.8150 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9165 - auc: 0.8735 - val_loss: 0.9748 - val_auc: 0.8109 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9177 - auc: 0.8718 - val_loss: 0.9750 - val_auc: 0.8108 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9041 - auc: 0.8824Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9041 - auc: 0.8824 - val_loss: 0.9749 - val_auc: 0.8104 - lr: 1.0000e-06\n",
      "Epoch 13: early stopping\n",
      "[===                                               ] 6.25%\u001B[92mModel: DenseNet121 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 18s 134ms/step - loss: 2.1144 - auc: 0.6986 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[===                                               ] 7.81%\u001B[92mModel: DenseNet121 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 18s 135ms/step - loss: 0.4989 - auc: 0.6179 - val_loss: 0.8823 - val_auc: 0.5815 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.3333 - auc: 0.6764 - val_loss: 0.5625 - val_auc: 0.6134 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.3279 - auc: 0.7228 - val_loss: 0.7008 - val_auc: 0.6613 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.2548 - auc: 0.7438\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.2548 - auc: 0.7438 - val_loss: 0.1937 - val_auc: 0.7446 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1515 - auc: 0.7815 - val_loss: 0.0902 - val_auc: 0.7832 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1351 - auc: 0.7833 - val_loss: 0.0735 - val_auc: 0.7985 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1101 - auc: 0.8061\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1101 - auc: 0.8061 - val_loss: 0.0735 - val_auc: 0.7738 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1138 - auc: 0.8077 - val_loss: 0.0737 - val_auc: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1063 - auc: 0.8128 - val_loss: 0.0692 - val_auc: 0.7966 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0991 - auc: 0.8055\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.0991 - auc: 0.8055 - val_loss: 0.0732 - val_auc: 0.7992 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.1053 - auc: 0.8130 - val_loss: 0.0724 - val_auc: 0.7994 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0950 - auc: 0.8278 - val_loss: 0.0728 - val_auc: 0.7993 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0927 - auc: 0.8234\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0927 - auc: 0.8234 - val_loss: 0.0721 - val_auc: 0.7984 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0979 - auc: 0.8207 - val_loss: 0.0739 - val_auc: 0.7988 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.1023 - auc: 0.8127 - val_loss: 0.0742 - val_auc: 0.7984 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1093 - auc: 0.8051Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "96/96 [==============================] - 12s 125ms/step - loss: 0.1093 - auc: 0.8051 - val_loss: 0.0737 - val_auc: 0.7986 - lr: 1.0000e-06\n",
      "Epoch 16: early stopping\n",
      "[====                                              ] 9.38%\u001B[92mModel: DenseNet121 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 18s 142ms/step - loss: 1.0102 - auc: 0.7013 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[=====                                             ] 10.94%\u001B[92mModel: DenseNet121 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 19s 143ms/step - loss: 1.0797 - auc: 0.6212 - val_loss: 1.1612 - val_auc: 0.5035 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 1.0488 - auc: 0.6538 - val_loss: 1.0665 - val_auc: 0.6409 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 130ms/step - loss: 1.0521 - auc: 0.6541 - val_loss: 1.0925 - val_auc: 0.5980 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0358 - auc: 0.6728\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 1.0358 - auc: 0.6728 - val_loss: 1.0500 - val_auc: 0.6590 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 1.0086 - auc: 0.7096 - val_loss: 1.0155 - val_auc: 0.6941 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 1.0105 - auc: 0.7088 - val_loss: 1.0308 - val_auc: 0.6856 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0011 - auc: 0.7172\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 1.0011 - auc: 0.7172 - val_loss: 1.0279 - val_auc: 0.6740 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 1.0013 - auc: 0.7158 - val_loss: 1.0294 - val_auc: 0.6761 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0050 - auc: 0.7140 - val_loss: 1.0313 - val_auc: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0027 - auc: 0.7169Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 12s 127ms/step - loss: 1.0027 - auc: 0.7169 - val_loss: 1.0318 - val_auc: 0.6789 - lr: 1.0000e-04\n",
      "Epoch 10: early stopping\n",
      "[======                                            ] 12.50%\u001B[92mModel: EfficientNetV2L - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 37s 196ms/step - loss: 2.0993 - auc: 0.6993 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[=======                                           ] 14.06%\u001B[92mModel: EfficientNetV2L - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 36s 178ms/step - loss: 0.2651 - auc: 0.5373 - val_loss: 0.2362 - val_auc: 0.3882 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.2130 - auc: 0.5791 - val_loss: 0.3042 - val_auc: 0.4656 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.1860 - auc: 0.5807 - val_loss: 0.1103 - val_auc: 0.6388 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1429 - auc: 0.6353\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1429 - auc: 0.6353 - val_loss: 0.0756 - val_auc: 0.5251 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1308 - auc: 0.6298 - val_loss: 0.0678 - val_auc: 0.6402 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1313 - auc: 0.6236 - val_loss: 0.0645 - val_auc: 0.7072 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1296 - auc: 0.6281\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1296 - auc: 0.6281 - val_loss: 0.0725 - val_auc: 0.7039 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1236 - auc: 0.6373 - val_loss: 0.0677 - val_auc: 0.7042 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1339 - auc: 0.6047 - val_loss: 0.0687 - val_auc: 0.7005 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1179 - auc: 0.6249\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1179 - auc: 0.6249 - val_loss: 0.0676 - val_auc: 0.6999 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1259 - auc: 0.6180Restoring model weights from the end of the best epoch: 6.\n",
      "96/96 [==============================] - 12s 119ms/step - loss: 0.1259 - auc: 0.6180 - val_loss: 0.0669 - val_auc: 0.6972 - lr: 1.0000e-06\n",
      "Epoch 11: early stopping\n",
      "[=======                                           ] 15.62%\u001B[92mModel: EfficientNetV2L - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 36s 182ms/step - loss: 1.0130 - auc: 0.6996 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 12s 125ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[========                                          ] 17.19%\u001B[92mModel: EfficientNetV2L - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 36s 179ms/step - loss: 1.1144 - auc: 0.5543 - val_loss: 1.1953 - val_auc: 0.4307 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 1.0850 - auc: 0.5907 - val_loss: 1.2220 - val_auc: 0.4317 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0752 - auc: 0.6134 - val_loss: 1.1906 - val_auc: 0.4029 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0715 - auc: 0.6243 - val_loss: 1.1243 - val_auc: 0.5756 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0667 - auc: 0.6243 - val_loss: 1.0687 - val_auc: 0.6072 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0635 - auc: 0.6296\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0635 - auc: 0.6296 - val_loss: 1.0768 - val_auc: 0.6151 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 1.0565 - auc: 0.6451 - val_loss: 1.0754 - val_auc: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 12s 119ms/step - loss: 1.0588 - auc: 0.6364 - val_loss: 1.0756 - val_auc: 0.6116 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0514 - auc: 0.6509\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0514 - auc: 0.6509 - val_loss: 1.0754 - val_auc: 0.6110 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 1.0548 - auc: 0.6424 - val_loss: 1.0751 - val_auc: 0.6191 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 1.0526 - auc: 0.6439 - val_loss: 1.0757 - val_auc: 0.6191 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0553 - auc: 0.6416\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0553 - auc: 0.6416 - val_loss: 1.0755 - val_auc: 0.6170 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0520 - auc: 0.6446 - val_loss: 1.0757 - val_auc: 0.6183 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0523 - auc: 0.6481 - val_loss: 1.0754 - val_auc: 0.6184 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0522 - auc: 0.6455\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0522 - auc: 0.6455 - val_loss: 1.0756 - val_auc: 0.6176 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0540 - auc: 0.6516Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 1.0540 - auc: 0.6516 - val_loss: 1.0757 - val_auc: 0.6183 - lr: 1.0000e-07\n",
      "Epoch 16: early stopping\n",
      "[=========                                         ] 18.75%\u001B[92mModel: EfficientNetV2L - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 36s 181ms/step - loss: 2.1446 - auc: 0.6946 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 2.1259 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[==========                                        ] 20.31%\u001B[92mModel: EfficientNetV2L - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 37s 185ms/step - loss: 0.6162 - auc: 0.6260 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 119ms/step - loss: 0.3675 - auc: 0.6161 - val_loss: 1.3347 - val_auc: 0.6800 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.3449 - auc: 0.6314 - val_loss: 0.7267 - val_auc: 0.6269 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.2731 - auc: 0.6164 - val_loss: 0.3182 - val_auc: 0.6111 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.2498 - auc: 0.6138 - val_loss: 0.2879 - val_auc: 0.6270 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1892 - auc: 0.6176 - val_loss: 0.2477 - val_auc: 0.5882 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1743 - auc: 0.6209Restoring model weights from the end of the best epoch: 2.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1743 - auc: 0.6209 - val_loss: 0.0846 - val_auc: 0.6664 - lr: 0.0100\n",
      "Epoch 7: early stopping\n",
      "[==========                                        ] 21.88%\u001B[92mModel: EfficientNetV2L - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 36s 176ms/step - loss: 1.0130 - auc: 0.6993 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[===========                                       ] 23.44%\u001B[92mModel: EfficientNetV2L - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 37s 184ms/step - loss: 1.0931 - auc: 0.5988 - val_loss: 1.2340 - val_auc: 0.4136 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0479 - auc: 0.6535 - val_loss: 1.2340 - val_auc: 0.4136 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 13s 133ms/step - loss: 1.0094 - auc: 0.7005 - val_loss: 1.0422 - val_auc: 0.6551 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7003\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7003 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 4.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 9: early stopping\n",
      "[============                                      ] 25.00%\u001B[92mModel: EfficientNetV2M - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 31s 169ms/step - loss: 4.1023 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 4.1755 - auc: 0.4123\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 4.1755 - auc: 0.4123Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[=============                                     ] 26.56%\u001B[92mModel: EfficientNetV2M - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 30s 161ms/step - loss: 0.2686 - auc: 0.5583 - val_loss: 0.2011 - val_auc: 0.6743 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.2034 - auc: 0.5858 - val_loss: 0.1660 - val_auc: 0.6882 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.1885 - auc: 0.6015 - val_loss: 0.3615 - val_auc: 0.6215 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.1696 - auc: 0.5821 - val_loss: 0.0969 - val_auc: 0.6246 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1355 - auc: 0.6201 - val_loss: 0.0807 - val_auc: 0.6860 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1358 - auc: 0.6289\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1358 - auc: 0.6289 - val_loss: 0.0925 - val_auc: 0.6655 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1147 - auc: 0.6174 - val_loss: 0.0607 - val_auc: 0.7295 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1175 - auc: 0.6072 - val_loss: 0.0671 - val_auc: 0.6961 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1096 - auc: 0.6380\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1096 - auc: 0.6380 - val_loss: 0.0621 - val_auc: 0.7169 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1217 - auc: 0.5961 - val_loss: 0.0628 - val_auc: 0.7024 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1080 - auc: 0.6264 - val_loss: 0.0628 - val_auc: 0.7013 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1061 - auc: 0.6283Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1061 - auc: 0.6283 - val_loss: 0.0630 - val_auc: 0.7014 - lr: 1.0000e-05\n",
      "Epoch 12: early stopping\n",
      "[==============                                    ] 28.12%\u001B[92mModel: EfficientNetV2M - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 29s 178ms/step - loss: 1.0119 - auc: 0.6986 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[==============                                    ] 29.69%\u001B[92mModel: EfficientNetV2M - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 30s 159ms/step - loss: 1.0912 - auc: 0.5967 - val_loss: 1.1841 - val_auc: 0.3844 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0848 - auc: 0.6128 - val_loss: 1.1655 - val_auc: 0.4949 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0736 - auc: 0.6283 - val_loss: 1.2339 - val_auc: 0.4136 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0754 - auc: 0.6341 - val_loss: 1.2236 - val_auc: 0.3545 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0668 - auc: 0.6314 - val_loss: 1.1631 - val_auc: 0.4795 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0515 - auc: 0.6590 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0182 - auc: 0.7109\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0182 - auc: 0.7109 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0142 - auc: 0.7067 - val_loss: 1.0419 - val_auc: 0.6614 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0125 - auc: 0.7064 - val_loss: 1.0418 - val_auc: 0.6805 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0112 - auc: 0.7152\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0112 - auc: 0.7152 - val_loss: 1.0417 - val_auc: 0.6759 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0135 - auc: 0.7146 - val_loss: 1.0417 - val_auc: 0.6758 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0129 - auc: 0.7083 - val_loss: 1.0417 - val_auc: 0.6761 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0115 - auc: 0.7108\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0115 - auc: 0.7108 - val_loss: 1.0417 - val_auc: 0.6778 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0121 - auc: 0.7083Restoring model weights from the end of the best epoch: 9.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 1.0121 - auc: 0.7083 - val_loss: 1.0417 - val_auc: 0.6786 - lr: 1.0000e-06\n",
      "Epoch 14: early stopping\n",
      "[===============                                   ] 31.25%\u001B[92mModel: EfficientNetV2M - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 31s 179ms/step - loss: 2.1037 - auc: 0.7016 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[================                                  ] 32.81%\u001B[92mModel: EfficientNetV2M - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 34s 198ms/step - loss: 0.4033 - auc: 0.5650 - val_loss: 1.2799 - val_auc: 0.6635 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.4441 - auc: 0.6421 - val_loss: 0.8651 - val_auc: 0.6285 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.3731 - auc: 0.6043 - val_loss: 0.2314 - val_auc: 0.6292 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.2534 - auc: 0.6435 - val_loss: 0.1627 - val_auc: 0.6794 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.2003 - auc: 0.5973\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.2003 - auc: 0.5973 - val_loss: 0.2362 - val_auc: 0.6601 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.1488 - auc: 0.6414 - val_loss: 0.0849 - val_auc: 0.6969 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1358 - auc: 0.5952 - val_loss: 0.0813 - val_auc: 0.5974 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1270 - auc: 0.6148 - val_loss: 0.0705 - val_auc: 0.6807 - lr: 1.0000e-03\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1257 - auc: 0.5879 - val_loss: 0.0805 - val_auc: 0.6278 - lr: 1.0000e-03\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1079 - auc: 0.6394\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1079 - auc: 0.6394 - val_loss: 0.0689 - val_auc: 0.6323 - lr: 1.0000e-03\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1000 - auc: 0.6299Restoring model weights from the end of the best epoch: 6.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1000 - auc: 0.6299 - val_loss: 0.0625 - val_auc: 0.6957 - lr: 1.0000e-04\n",
      "Epoch 11: early stopping\n",
      "[=================                                 ] 34.38%\u001B[92mModel: EfficientNetV2M - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 30s 168ms/step - loss: 1.0094 - auc: 0.7016 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[=================                                 ] 35.94%\u001B[92mModel: EfficientNetV2M - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 30s 159ms/step - loss: 1.0971 - auc: 0.5942 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0837 - auc: 0.6076 - val_loss: 1.1018 - val_auc: 0.5895 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0315 - auc: 0.6791 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7006 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[==================                                ] 37.50%\u001B[92mModel: VGG16 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 13s 121ms/step - loss: 0.0558 - auc: 0.7574 - val_loss: 0.0583 - val_auc: 0.7047 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 110ms/step - loss: 0.0468 - auc: 0.8420 - val_loss: 0.0651 - val_auc: 0.7662 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0434 - auc: 0.8640 - val_loss: 0.0719 - val_auc: 0.7885 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0413 - auc: 0.8840\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0413 - auc: 0.8840 - val_loss: 0.0494 - val_auc: 0.8161 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0342 - auc: 0.9357 - val_loss: 0.0525 - val_auc: 0.8150 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.0336 - auc: 0.9334 - val_loss: 0.0523 - val_auc: 0.8191 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0328 - auc: 0.9376\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0328 - auc: 0.9376 - val_loss: 0.0520 - val_auc: 0.8227 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.0319 - auc: 0.9394 - val_loss: 0.0506 - val_auc: 0.8256 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 110ms/step - loss: 0.0318 - auc: 0.9421 - val_loss: 0.0505 - val_auc: 0.8259 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0317 - auc: 0.9428\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0317 - auc: 0.9428 - val_loss: 0.0502 - val_auc: 0.8261 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 13s 137ms/step - loss: 0.0316 - auc: 0.9439 - val_loss: 0.0503 - val_auc: 0.8263 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.0316 - auc: 0.9438 - val_loss: 0.0503 - val_auc: 0.8262 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0316 - auc: 0.9436\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0316 - auc: 0.9436 - val_loss: 0.0503 - val_auc: 0.8260 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0316 - auc: 0.9435 - val_loss: 0.0503 - val_auc: 0.8260 - lr: 1.0000e-07\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.0316 - auc: 0.9436 - val_loss: 0.0503 - val_auc: 0.8260 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0316 - auc: 0.9435Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0316 - auc: 0.9435 - val_loss: 0.0503 - val_auc: 0.8260 - lr: 1.0000e-07\n",
      "Epoch 16: early stopping\n",
      "[===================                               ] 39.06%\u001B[92mModel: VGG16 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 12s 117ms/step - loss: 0.2999 - auc: 0.6251 - val_loss: 0.1215 - val_auc: 0.7307 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1994 - auc: 0.7190 - val_loss: 0.1194 - val_auc: 0.7666 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1666 - auc: 0.7459 - val_loss: 0.0594 - val_auc: 0.8111 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1262 - auc: 0.7906\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1262 - auc: 0.7906 - val_loss: 0.0823 - val_auc: 0.7771 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.1048 - auc: 0.8187 - val_loss: 0.0803 - val_auc: 0.7753 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0875 - auc: 0.8333 - val_loss: 0.0718 - val_auc: 0.8066 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0935 - auc: 0.8200\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.0935 - auc: 0.8200 - val_loss: 0.0689 - val_auc: 0.8193 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0918 - auc: 0.8302 - val_loss: 0.0700 - val_auc: 0.8181 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.0853 - auc: 0.8446 - val_loss: 0.0690 - val_auc: 0.8188 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0962 - auc: 0.8275\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0962 - auc: 0.8275 - val_loss: 0.0697 - val_auc: 0.8175 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.0872 - auc: 0.8446 - val_loss: 0.0693 - val_auc: 0.8184 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0856 - auc: 0.8476Restoring model weights from the end of the best epoch: 7.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0856 - auc: 0.8476 - val_loss: 0.0702 - val_auc: 0.8174 - lr: 1.0000e-06\n",
      "Epoch 12: early stopping\n",
      "[====================                              ] 40.62%\u001B[92mModel: VGG16 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 12s 116ms/step - loss: 1.0129 - auc: 0.6976 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[=====================                             ] 42.19%\u001B[92mModel: VGG16 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 12s 118ms/step - loss: 1.0524 - auc: 0.6815 - val_loss: 1.0358 - val_auc: 0.7379 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0081 - auc: 0.7424 - val_loss: 1.0339 - val_auc: 0.7445 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9824 - auc: 0.7837 - val_loss: 1.0414 - val_auc: 0.6953 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9633 - auc: 0.8197 - val_loss: 1.0167 - val_auc: 0.7342 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9476 - auc: 0.8235 - val_loss: 1.0129 - val_auc: 0.7411 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9337 - auc: 0.8403\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9337 - auc: 0.8403 - val_loss: 0.9873 - val_auc: 0.7613 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.9163 - auc: 0.8552 - val_loss: 0.9800 - val_auc: 0.7749 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.9096 - auc: 0.8654 - val_loss: 0.9806 - val_auc: 0.7726 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9019 - auc: 0.8675\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9019 - auc: 0.8675 - val_loss: 0.9829 - val_auc: 0.7753 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.8979 - auc: 0.8776 - val_loss: 0.9821 - val_auc: 0.7775 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.8902 - auc: 0.8791 - val_loss: 0.9831 - val_auc: 0.7770 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9024 - auc: 0.8757\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9024 - auc: 0.8757 - val_loss: 0.9838 - val_auc: 0.7741 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.8977 - auc: 0.8784 - val_loss: 0.9842 - val_auc: 0.7789 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9085 - auc: 0.8678 - val_loss: 0.9843 - val_auc: 0.7787 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.8931 - auc: 0.8783\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.8931 - auc: 0.8783 - val_loss: 0.9847 - val_auc: 0.7767 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.8990 - auc: 0.8802 - val_loss: 0.9846 - val_auc: 0.7785 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.8954 - auc: 0.8738 - val_loss: 0.9848 - val_auc: 0.7789 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.8976 - auc: 0.8779\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.8976 - auc: 0.8779 - val_loss: 0.9844 - val_auc: 0.7781 - lr: 1.0000e-07\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.8960 - auc: 0.8753 - val_loss: 0.9850 - val_auc: 0.7785 - lr: 1.0000e-08\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.8993 - auc: 0.8765 - val_loss: 0.9843 - val_auc: 0.7785 - lr: 1.0000e-08\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9001 - auc: 0.8778\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.9001 - auc: 0.8778 - val_loss: 0.9841 - val_auc: 0.7788 - lr: 1.0000e-08\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9017 - auc: 0.8681Restoring model weights from the end of the best epoch: 17.\n",
      "96/96 [==============================] - 13s 132ms/step - loss: 0.9017 - auc: 0.8681 - val_loss: 0.9840 - val_auc: 0.7787 - lr: 1.0000e-09\n",
      "Epoch 22: early stopping\n",
      "[=====================                             ] 43.75%\u001B[92mModel: VGG16 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 13s 127ms/step - loss: 0.0878 - auc: 0.7037 - val_loss: 0.0550 - val_auc: 0.7521 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 128ms/step - loss: 0.0468 - auc: 0.8371 - val_loss: 0.0519 - val_auc: 0.7891 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 125ms/step - loss: 0.0441 - auc: 0.8587 - val_loss: 0.0504 - val_auc: 0.8136 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0438 - auc: 0.8644\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 12s 127ms/step - loss: 0.0438 - auc: 0.8644 - val_loss: 0.0515 - val_auc: 0.7889 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.0359 - auc: 0.9241 - val_loss: 0.0529 - val_auc: 0.8123 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0331 - auc: 0.9325 - val_loss: 0.0521 - val_auc: 0.8200 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0314 - auc: 0.9394\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.0314 - auc: 0.9394 - val_loss: 0.0525 - val_auc: 0.8148 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 12s 129ms/step - loss: 0.0305 - auc: 0.9441 - val_loss: 0.0523 - val_auc: 0.8220 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0302 - auc: 0.9460 - val_loss: 0.0527 - val_auc: 0.8224 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0300 - auc: 0.9464\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0300 - auc: 0.9464 - val_loss: 0.0532 - val_auc: 0.8231 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 0.0298 - auc: 0.9467 - val_loss: 0.0532 - val_auc: 0.8233 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 13s 132ms/step - loss: 0.0298 - auc: 0.9468 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0298 - auc: 0.9468\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "96/96 [==============================] - 12s 128ms/step - loss: 0.0298 - auc: 0.9468 - val_loss: 0.0531 - val_auc: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 12s 127ms/step - loss: 0.0298 - auc: 0.9469 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 12s 130ms/step - loss: 0.0298 - auc: 0.9469 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0298 - auc: 0.9469\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "96/96 [==============================] - 13s 133ms/step - loss: 0.0298 - auc: 0.9469 - val_loss: 0.0531 - val_auc: 0.8239 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 13s 133ms/step - loss: 0.0298 - auc: 0.9469 - val_loss: 0.0531 - val_auc: 0.8239 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 12s 125ms/step - loss: 0.0298 - auc: 0.9469 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-07\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0298 - auc: 0.9469\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 0.0298 - auc: 0.9469 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-07\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 0.0298 - auc: 0.9470 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-08\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0298 - auc: 0.9470Restoring model weights from the end of the best epoch: 16.\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 0.0298 - auc: 0.9470 - val_loss: 0.0531 - val_auc: 0.8238 - lr: 1.0000e-08\n",
      "Epoch 21: early stopping\n",
      "[======================                            ] 45.31%\u001B[92mModel: VGG16 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 14s 131ms/step - loss: 0.4682 - auc: 0.6351 - val_loss: 1.0272 - val_auc: 0.6174 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.4283 - auc: 0.6835 - val_loss: 0.9096 - val_auc: 0.5461 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 13s 132ms/step - loss: 0.3525 - auc: 0.7045 - val_loss: 0.4660 - val_auc: 0.7141 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 0.3187 - auc: 0.7201 - val_loss: 0.2429 - val_auc: 0.6722 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1916 - auc: 0.7583\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.1916 - auc: 0.7583 - val_loss: 0.1672 - val_auc: 0.7585 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 0.1236 - auc: 0.7978 - val_loss: 0.0870 - val_auc: 0.7967 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 0.1044 - auc: 0.8153 - val_loss: 0.0631 - val_auc: 0.8083 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1044 - auc: 0.8102\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 12s 130ms/step - loss: 0.1044 - auc: 0.8102 - val_loss: 0.0821 - val_auc: 0.7832 - lr: 1.0000e-03\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.1058 - auc: 0.8050 - val_loss: 0.0809 - val_auc: 0.7907 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1094 - auc: 0.8020 - val_loss: 0.0718 - val_auc: 0.8048 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0954 - auc: 0.8180\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 0.0954 - auc: 0.8180 - val_loss: 0.0724 - val_auc: 0.8048 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0941 - auc: 0.8218Restoring model weights from the end of the best epoch: 7.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.0941 - auc: 0.8218 - val_loss: 0.0724 - val_auc: 0.8059 - lr: 1.0000e-05\n",
      "Epoch 12: early stopping\n",
      "[=======================                           ] 46.88%\u001B[92mModel: VGG16 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 13s 126ms/step - loss: 1.0099 - auc: 0.7012 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[========================                          ] 48.44%\u001B[92mModel: VGG16 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 13s 123ms/step - loss: 1.0308 - auc: 0.6957 - val_loss: 1.0667 - val_auc: 0.6363 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0179 - auc: 0.6999 - val_loss: 1.0384 - val_auc: 0.6629 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0097 - auc: 0.7129 - val_loss: 1.0292 - val_auc: 0.6785 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0028 - auc: 0.7183\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0028 - auc: 0.7183 - val_loss: 1.0420 - val_auc: 0.6592 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.9873 - auc: 0.7422 - val_loss: 1.0316 - val_auc: 0.6701 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9862 - auc: 0.7341 - val_loss: 1.0290 - val_auc: 0.6766 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9873 - auc: 0.7418\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.9873 - auc: 0.7418 - val_loss: 1.0263 - val_auc: 0.6801 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.9862 - auc: 0.7348 - val_loss: 1.0288 - val_auc: 0.6858 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.9858 - auc: 0.7375 - val_loss: 1.0259 - val_auc: 0.6863 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9849 - auc: 0.7409\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 0.9849 - auc: 0.7409 - val_loss: 1.0276 - val_auc: 0.6881 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.9883 - auc: 0.7337 - val_loss: 1.0285 - val_auc: 0.6857 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9838 - auc: 0.7403 - val_loss: 1.0279 - val_auc: 0.6849 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9867 - auc: 0.7367\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.9867 - auc: 0.7367 - val_loss: 1.0290 - val_auc: 0.6854 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9861 - auc: 0.7390 - val_loss: 1.0283 - val_auc: 0.6849 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9881 - auc: 0.7369Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9881 - auc: 0.7369 - val_loss: 1.0284 - val_auc: 0.6863 - lr: 1.0000e-06\n",
      "Epoch 15: early stopping\n",
      "[=========================                         ] 50.00%\u001B[92mModel: ResNet50 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 16s 135ms/step - loss: 0.2174 - auc: 0.6287 - val_loss: 0.0891 - val_auc: 0.5427 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0641 - auc: 0.6760 - val_loss: 0.0691 - val_auc: 0.7063 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.0636 - auc: 0.6917 - val_loss: 0.0574 - val_auc: 0.7247 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0683 - auc: 0.6992\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0683 - auc: 0.6992 - val_loss: 0.0780 - val_auc: 0.5580 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0558 - auc: 0.7430 - val_loss: 0.0576 - val_auc: 0.7138 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0543 - auc: 0.7576 - val_loss: 0.0625 - val_auc: 0.7332 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0548 - auc: 0.7520\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0548 - auc: 0.7520 - val_loss: 0.0569 - val_auc: 0.7271 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0531 - auc: 0.7850 - val_loss: 0.0569 - val_auc: 0.7300 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0531 - auc: 0.7882 - val_loss: 0.0573 - val_auc: 0.7249 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0532 - auc: 0.7860\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0532 - auc: 0.7860 - val_loss: 0.0570 - val_auc: 0.7358 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0529 - auc: 0.7968 - val_loss: 0.0570 - val_auc: 0.7316 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0530 - auc: 0.7930 - val_loss: 0.0570 - val_auc: 0.7306 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0529 - auc: 0.7941\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0529 - auc: 0.7941 - val_loss: 0.0570 - val_auc: 0.7296 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0529 - auc: 0.7951 - val_loss: 0.0570 - val_auc: 0.7296 - lr: 1.0000e-07\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0529 - auc: 0.7949Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.0529 - auc: 0.7949 - val_loss: 0.0570 - val_auc: 0.7287 - lr: 1.0000e-07\n",
      "Epoch 15: early stopping\n",
      "[=========================                         ] 51.56%\u001B[92mModel: ResNet50 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 16s 132ms/step - loss: 0.2582 - auc: 0.6258 - val_loss: 0.2282 - val_auc: 0.6597 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1822 - auc: 0.6820 - val_loss: 0.3312 - val_auc: 0.6980 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1714 - auc: 0.6839 - val_loss: 0.0919 - val_auc: 0.7269 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1333 - auc: 0.7230\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1333 - auc: 0.7230 - val_loss: 0.1065 - val_auc: 0.7047 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1236 - auc: 0.7272 - val_loss: 0.1306 - val_auc: 0.7424 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1136 - auc: 0.7431 - val_loss: 0.0699 - val_auc: 0.7596 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1128 - auc: 0.7491\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1128 - auc: 0.7491 - val_loss: 0.0756 - val_auc: 0.7754 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1062 - auc: 0.7638 - val_loss: 0.0702 - val_auc: 0.7788 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1020 - auc: 0.7635 - val_loss: 0.0645 - val_auc: 0.7823 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0993 - auc: 0.7764\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0993 - auc: 0.7764 - val_loss: 0.0629 - val_auc: 0.7816 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1005 - auc: 0.7593 - val_loss: 0.0630 - val_auc: 0.7834 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.1023 - auc: 0.7623 - val_loss: 0.0643 - val_auc: 0.7833 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1073 - auc: 0.7508\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.1073 - auc: 0.7508 - val_loss: 0.0642 - val_auc: 0.7832 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1108 - auc: 0.7525 - val_loss: 0.0626 - val_auc: 0.7856 - lr: 1.0000e-07\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1035 - auc: 0.7620 - val_loss: 0.0632 - val_auc: 0.7859 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1067 - auc: 0.7571\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1067 - auc: 0.7571 - val_loss: 0.0636 - val_auc: 0.7838 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1008 - auc: 0.7684 - val_loss: 0.0635 - val_auc: 0.7854 - lr: 1.0000e-08\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0997 - auc: 0.7650 - val_loss: 0.0639 - val_auc: 0.7844 - lr: 1.0000e-08\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1042 - auc: 0.7583\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1042 - auc: 0.7583 - val_loss: 0.0630 - val_auc: 0.7857 - lr: 1.0000e-08\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1076 - auc: 0.7466 - val_loss: 0.0640 - val_auc: 0.7860 - lr: 1.0000e-09\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1129 - auc: 0.7551 - val_loss: 0.0633 - val_auc: 0.7867 - lr: 1.0000e-09\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1067 - auc: 0.7708\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1067 - auc: 0.7708 - val_loss: 0.0636 - val_auc: 0.7861 - lr: 1.0000e-09\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1012 - auc: 0.7761 - val_loss: 0.0627 - val_auc: 0.7869 - lr: 1.0000e-10\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1124 - auc: 0.7438 - val_loss: 0.0630 - val_auc: 0.7853 - lr: 1.0000e-10\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1028 - auc: 0.7596\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.1028 - auc: 0.7596 - val_loss: 0.0641 - val_auc: 0.7850 - lr: 1.0000e-10\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.1094 - auc: 0.7646 - val_loss: 0.0634 - val_auc: 0.7863 - lr: 1.0000e-11\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0985 - auc: 0.7659 - val_loss: 0.0645 - val_auc: 0.7833 - lr: 1.0000e-11\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1046 - auc: 0.7669Restoring model weights from the end of the best epoch: 23.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1046 - auc: 0.7669 - val_loss: 0.0641 - val_auc: 0.7831 - lr: 1.0000e-11\n",
      "Epoch 28: early stopping\n",
      "[==========================                        ] 53.12%\u001B[92mModel: ResNet50 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 133ms/step - loss: 1.2354 - auc: 0.4115 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 1.2350 - auc: 0.4123 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.2350 - auc: 0.4123 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.2350 - auc: 0.4123\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.2350 - auc: 0.4123 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.2350 - auc: 0.4123 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.2350 - auc: 0.4123Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.2350 - auc: 0.4123 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[===========================                       ] 54.69%\u001B[92mModel: ResNet50 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 130ms/step - loss: 1.0791 - auc: 0.6395 - val_loss: 1.2323 - val_auc: 0.3907 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0198 - auc: 0.7440 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0029 - auc: 0.7635 - val_loss: 1.0380 - val_auc: 0.6715 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9957 - auc: 0.7710\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.9957 - auc: 0.7710 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.9618 - auc: 0.8145 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.9672 - auc: 0.8194 - val_loss: 1.0195 - val_auc: 0.7111 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9527 - auc: 0.8363\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9527 - auc: 0.8363 - val_loss: 1.0203 - val_auc: 0.7213 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9627 - auc: 0.8259 - val_loss: 1.0053 - val_auc: 0.7490 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9491 - auc: 0.8333 - val_loss: 1.0036 - val_auc: 0.7538 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9566 - auc: 0.8336\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9566 - auc: 0.8336 - val_loss: 1.0012 - val_auc: 0.7614 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9433 - auc: 0.8395 - val_loss: 1.0015 - val_auc: 0.7681 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9466 - auc: 0.8443 - val_loss: 1.0020 - val_auc: 0.7678 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9495 - auc: 0.8390\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9495 - auc: 0.8390 - val_loss: 1.0018 - val_auc: 0.7690 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9572 - auc: 0.8329 - val_loss: 1.0020 - val_auc: 0.7649 - lr: 1.0000e-07\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9511 - auc: 0.8372 - val_loss: 1.0013 - val_auc: 0.7680 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9514 - auc: 0.8314\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9514 - auc: 0.8314 - val_loss: 1.0022 - val_auc: 0.7667 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 0.9539 - auc: 0.8324 - val_loss: 1.0025 - val_auc: 0.7685 - lr: 1.0000e-08\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9548 - auc: 0.8327Restoring model weights from the end of the best epoch: 13.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9548 - auc: 0.8327 - val_loss: 1.0021 - val_auc: 0.7678 - lr: 1.0000e-08\n",
      "Epoch 18: early stopping\n",
      "[============================                      ] 56.25%\u001B[92mModel: ResNet50 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 16s 140ms/step - loss: 2.1074 - auc: 0.7003 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 2.1260 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[============================                      ] 57.81%\u001B[92mModel: ResNet50 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 16s 130ms/step - loss: 0.4719 - auc: 0.6458 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.4013 - auc: 0.6619 - val_loss: 1.9900 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.2894 - auc: 0.6887 - val_loss: 1.0760 - val_auc: 0.6916 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.2933 - auc: 0.6818 - val_loss: 1.5105 - val_auc: 0.4868 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 12s 119ms/step - loss: 0.2432 - auc: 0.6868 - val_loss: 0.2961 - val_auc: 0.3959 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.1933 - auc: 0.7287 - val_loss: 0.2257 - val_auc: 0.5884 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1552 - auc: 0.6862 - val_loss: 0.7391 - val_auc: 0.7033 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1281 - auc: 0.7076\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1281 - auc: 0.7076 - val_loss: 0.1333 - val_auc: 0.7082 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0919 - auc: 0.7529 - val_loss: 0.0779 - val_auc: 0.7599 - lr: 1.0000e-03\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0871 - auc: 0.7243 - val_loss: 0.0623 - val_auc: 0.7609 - lr: 1.0000e-03\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0841 - auc: 0.7392\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0841 - auc: 0.7392 - val_loss: 0.0624 - val_auc: 0.7685 - lr: 1.0000e-03\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0815 - auc: 0.7523 - val_loss: 0.0618 - val_auc: 0.7660 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0727 - auc: 0.7656 - val_loss: 0.0595 - val_auc: 0.7688 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0735 - auc: 0.7554\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0735 - auc: 0.7554 - val_loss: 0.0575 - val_auc: 0.7712 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0747 - auc: 0.7548 - val_loss: 0.0572 - val_auc: 0.7721 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.0781 - auc: 0.7460 - val_loss: 0.0576 - val_auc: 0.7722 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0744 - auc: 0.7518\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0744 - auc: 0.7518 - val_loss: 0.0577 - val_auc: 0.7719 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0744 - auc: 0.7596 - val_loss: 0.0575 - val_auc: 0.7733 - lr: 1.0000e-06\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0783 - auc: 0.7484 - val_loss: 0.0564 - val_auc: 0.7745 - lr: 1.0000e-06\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0752 - auc: 0.7602\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0752 - auc: 0.7602 - val_loss: 0.0571 - val_auc: 0.7739 - lr: 1.0000e-06\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0787 - auc: 0.7530 - val_loss: 0.0571 - val_auc: 0.7725 - lr: 1.0000e-07\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0754 - auc: 0.7608 - val_loss: 0.0564 - val_auc: 0.7734 - lr: 1.0000e-07\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0786 - auc: 0.7395\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0786 - auc: 0.7395 - val_loss: 0.0568 - val_auc: 0.7741 - lr: 1.0000e-07\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0757 - auc: 0.7547Restoring model weights from the end of the best epoch: 19.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0757 - auc: 0.7547 - val_loss: 0.0566 - val_auc: 0.7738 - lr: 1.0000e-08\n",
      "Epoch 24: early stopping\n",
      "[=============================                     ] 59.38%\u001B[92mModel: ResNet50 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 132ms/step - loss: 1.0094 - auc: 0.7013 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[==============================                    ] 60.94%\u001B[92mModel: ResNet50 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 16s 132ms/step - loss: 1.0668 - auc: 0.6517 - val_loss: 1.2340 - val_auc: 0.4136 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 1.0336 - auc: 0.6742 - val_loss: 1.2340 - val_auc: 0.4136 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0197 - auc: 0.6976 - val_loss: 1.2289 - val_auc: 0.3477 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0085 - auc: 0.7056 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0111 - auc: 0.7023 - val_loss: 1.0884 - val_auc: 0.6059 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0111 - auc: 0.7015\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 1.0111 - auc: 0.7015 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 9: early stopping\n",
      "[===============================                   ] 62.50%\u001B[92mModel: InceptionV3 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[================================                  ] 64.06%\u001B[92mModel: InceptionV3 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[================================                  ] 65.62%\u001B[92mModel: InceptionV3 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[=================================                 ] 67.19%\u001B[92mModel: InceptionV3 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[==================================                ] 68.75%\u001B[92mModel: InceptionV3 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[===================================               ] 70.31%\u001B[92mModel: InceptionV3 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[===================================               ] 71.88%\u001B[92mModel: InceptionV3 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[====================================              ] 73.44%\u001B[92mModel: InceptionV3 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "\u001B[91mError:\u001B[0m Input size must be at least 75x75; Received: input_shape=(50, 50, 3)\n",
      "[=====================================             ] 75.00%\u001B[92mModel: MobileNetV2 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 1s 0us/step\n",
      "9420800/9406464 [==============================] - 1s 0us/step\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 16s 138ms/step - loss: 1.7257 - auc: 0.3529 - val_loss: 0.9597 - val_auc: 0.3951 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0044 - auc: 0.3542 - val_loss: 0.8708 - val_auc: 0.3832 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.9419 - auc: 0.3591 - val_loss: 0.8122 - val_auc: 0.4205 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.9155 - auc: 0.3756 - val_loss: 0.8318 - val_auc: 0.4089 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.8969 - auc: 0.3875\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.8969 - auc: 0.3875 - val_loss: 0.8180 - val_auc: 0.4020 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.8733 - auc: 0.4317 - val_loss: 0.8044 - val_auc: 0.4293 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.6877 - auc: 0.4696 - val_loss: 0.0904 - val_auc: 0.7011 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0517 - auc: 0.8120\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0517 - auc: 0.8120 - val_loss: 0.0550 - val_auc: 0.7594 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0434 - auc: 0.8832 - val_loss: 0.0552 - val_auc: 0.7683 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0426 - auc: 0.8883 - val_loss: 0.0548 - val_auc: 0.7686 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0420 - auc: 0.8924\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0420 - auc: 0.8924 - val_loss: 0.0542 - val_auc: 0.7690 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0417 - auc: 0.8995 - val_loss: 0.0542 - val_auc: 0.7706 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0415 - auc: 0.8989 - val_loss: 0.0543 - val_auc: 0.7723 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0415 - auc: 0.8983\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0415 - auc: 0.8983 - val_loss: 0.0543 - val_auc: 0.7736 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.0414 - auc: 0.8985 - val_loss: 0.0543 - val_auc: 0.7732 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0414 - auc: 0.8984 - val_loss: 0.0543 - val_auc: 0.7733 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0414 - auc: 0.8985\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0414 - auc: 0.8985 - val_loss: 0.0543 - val_auc: 0.7734 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0414 - auc: 0.8985 - val_loss: 0.0543 - val_auc: 0.7733 - lr: 1.0000e-08\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0414 - auc: 0.8985Restoring model weights from the end of the best epoch: 14.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.0414 - auc: 0.8985 - val_loss: 0.0543 - val_auc: 0.7733 - lr: 1.0000e-08\n",
      "Epoch 19: early stopping\n",
      "[======================================            ] 76.56%\u001B[92mModel: MobileNetV2 - LR: 0.001 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 123ms/step - loss: 0.2951 - auc: 0.6130 - val_loss: 0.4098 - val_auc: 0.5838 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.2060 - auc: 0.6900 - val_loss: 0.2567 - val_auc: 0.7126 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.1744 - auc: 0.7267 - val_loss: 0.1304 - val_auc: 0.6532 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1364 - auc: 0.7652\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.1364 - auc: 0.7652 - val_loss: 0.1301 - val_auc: 0.7740 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.1073 - auc: 0.8115 - val_loss: 0.0825 - val_auc: 0.7842 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0987 - auc: 0.8194 - val_loss: 0.0799 - val_auc: 0.7626 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0975 - auc: 0.8170\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.0975 - auc: 0.8170 - val_loss: 0.0897 - val_auc: 0.7734 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 0.0904 - auc: 0.8205 - val_loss: 0.0864 - val_auc: 0.7752 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0913 - auc: 0.8266 - val_loss: 0.0831 - val_auc: 0.7781 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0808 - auc: 0.8452Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0808 - auc: 0.8452 - val_loss: 0.0833 - val_auc: 0.7796 - lr: 1.0000e-05\n",
      "Epoch 10: early stopping\n",
      "[=======================================           ] 78.12%\u001B[92mModel: MobileNetV2 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 128ms/step - loss: 1.0132 - auc: 0.7000 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 14s 150ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[=======================================           ] 79.69%\u001B[92mModel: MobileNetV2 - LR: 0.001 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 17s 138ms/step - loss: 1.0808 - auc: 0.6192 - val_loss: 1.0728 - val_auc: 0.6236 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 1.0589 - auc: 0.6625 - val_loss: 1.0412 - val_auc: 0.7079 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 1.0221 - auc: 0.7160 - val_loss: 1.0190 - val_auc: 0.6968 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9998 - auc: 0.7558\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9998 - auc: 0.7558 - val_loss: 1.0426 - val_auc: 0.6828 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.9787 - auc: 0.7810 - val_loss: 1.0287 - val_auc: 0.6981 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 0.9658 - auc: 0.8028 - val_loss: 1.0163 - val_auc: 0.7126 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9470 - auc: 0.8232\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9470 - auc: 0.8232 - val_loss: 1.0040 - val_auc: 0.7342 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.9450 - auc: 0.8289 - val_loss: 1.0017 - val_auc: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.9380 - auc: 0.8272 - val_loss: 1.0015 - val_auc: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9362 - auc: 0.8336\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.9362 - auc: 0.8336 - val_loss: 1.0017 - val_auc: 0.7332 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.9406 - auc: 0.8335 - val_loss: 1.0019 - val_auc: 0.7336 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.9390 - auc: 0.8278Restoring model weights from the end of the best epoch: 7.\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.9390 - auc: 0.8278 - val_loss: 1.0020 - val_auc: 0.7328 - lr: 1.0000e-06\n",
      "Epoch 12: early stopping\n",
      "[========================================          ] 81.25%\u001B[92mModel: MobileNetV2 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: CAM\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 128ms/step - loss: 4.1309 - auc: 0.4119 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 4.1755 - auc: 0.4123\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 117ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 4.1755 - auc: 0.4123Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 4.1755 - auc: 0.4123 - val_loss: 4.0692 - val_auc: 0.4273 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[=========================================         ] 82.81%\u001B[92mModel: MobileNetV2 - LR: 0.01 - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x755253668790> - Top: Standard\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 15s 130ms/step - loss: 0.5033 - auc: 0.6117 - val_loss: 1.2179 - val_auc: 0.4541 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.3744 - auc: 0.6795 - val_loss: 0.5450 - val_auc: 0.6646 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.3023 - auc: 0.7238 - val_loss: 0.3602 - val_auc: 0.6844 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.2318 - auc: 0.7275\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.2318 - auc: 0.7275 - val_loss: 0.3319 - val_auc: 0.6428 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.1351 - auc: 0.7826 - val_loss: 0.0939 - val_auc: 0.7581 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.1132 - auc: 0.7996 - val_loss: 0.0988 - val_auc: 0.7655 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1068 - auc: 0.7903\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.1068 - auc: 0.7903 - val_loss: 0.0803 - val_auc: 0.7761 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.0872 - auc: 0.8183 - val_loss: 0.0807 - val_auc: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.0903 - auc: 0.8172 - val_loss: 0.0797 - val_auc: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0994 - auc: 0.7927\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.0994 - auc: 0.7927 - val_loss: 0.0785 - val_auc: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 11s 111ms/step - loss: 0.0925 - auc: 0.8168 - val_loss: 0.0790 - val_auc: 0.7785 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0900 - auc: 0.8323 - val_loss: 0.0781 - val_auc: 0.7790 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0968 - auc: 0.8095\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0968 - auc: 0.8095 - val_loss: 0.0788 - val_auc: 0.7772 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 0.0879 - auc: 0.8143 - val_loss: 0.0791 - val_auc: 0.7774 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0865 - auc: 0.8203Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 0.0865 - auc: 0.8203 - val_loss: 0.0787 - val_auc: 0.7776 - lr: 1.0000e-06\n",
      "Epoch 15: early stopping\n",
      "[==========================================        ] 84.38%\u001B[92mModel: MobileNetV2 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: CAM\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 14s 124ms/step - loss: 1.0108 - auc: 0.7016 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "96/96 [==============================] - 11s 114ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 11s 113ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "96/96 [==============================] - 11s 112ms/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[==========================================        ] 85.94%\u001B[92mModel: MobileNetV2 - LR: 0.01 - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x755253668280> - Top: Standard\u001B[0m\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
