{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-02T12:17:08.837349Z",
     "start_time": "2024-08-02T12:17:05.626721Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cell_division.nets.transfer_learning import CNN\n",
    "from auxiliary.data.dataset_cell import CellDataset\n",
    "from auxiliary import values as v\n",
    "from auxiliary.utils.colors import bcolors as c\n",
    "\n",
    "# from focal_loss import SparseCategoricalFocalLoss\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from cell_division.nets.custom_layers import w_cel_loss, focal_loss\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# GPU config\n",
    "from auxiliary.utils.timer import LoadingBar\n",
    "from auxiliary.gpu.gpu_tf import (\n",
    "    increase_gpu_memory, \n",
    "    set_gpu_allocator, \n",
    "    clear_session\n",
    ")\n",
    "\n",
    "increase_gpu_memory()\n",
    "set_gpu_allocator()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:17:08.843667Z",
     "start_time": "2024-08-02T12:17:08.839610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = v.data_path + 'CellDivision/images/'\n",
    "label_train_dir = v.data_path + 'CellDivision/train.csv'\n",
    "label_test_dir = v.data_path + 'CellDivision/test.csv'\n",
    "label_val_dir = v.data_path + 'CellDivision/val.csv'\n",
    "\n",
    "INPUT_SHAPE = (50, 50, 3)\n",
    "BATCH_SIZE = 64"
   ],
   "id": "72671286f4e09b93",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dataset (Generators)\n",
    "\n",
    "Generatos do not load directly the images into memory, but they load the images on the fly. This is useful when the dataset is too large to fit into memory."
   ],
   "id": "6a22a8984306870e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:17:08.873150Z",
     "start_time": "2024-08-02T12:17:08.845353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_train_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "val_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_val_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")"
   ],
   "id": "a54e19ea8c8c2bc9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transfer Learning ",
   "id": "bd19c08a9ae85271"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:17:08.877864Z",
     "start_time": "2024-08-02T12:17:08.874382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_models = {\n",
    "    'DenseNet121': tf.keras.applications.DenseNet121,\n",
    "    'EfficientNetV2L': tf.keras.applications.EfficientNetV2L,\n",
    "    'EfficientNetV2M': tf.keras.applications.EfficientNetV2M,\n",
    "    'VGG16': tf.keras.applications.VGG16,\n",
    "    'ResNet50': tf.keras.applications.ResNet50,\n",
    "    'InceptionV3': tf.keras.applications.InceptionV3,\n",
    "    'MobileNetV2': tf.keras.applications.MobileNetV2,\n",
    "    'NASNetMobile': tf.keras.applications.NASNetMobile,\n",
    "}\n"
   ],
   "id": "199d42b8fb6d8443",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:17:08.886023Z",
     "start_time": "2024-08-02T12:17:08.880913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'base_model': list(base_models.keys()),\n",
    "    'lr': [1e-3, 1e-2],\n",
    "    'fine_tune': [True, False],\n",
    "    'loss': [focal_loss(), w_cel_loss()],\n",
    "    'top': ['CAM', 'Standard'],\n",
    "    # 'class_weight': [None, 'balanced']\n",
    "}"
   ],
   "id": "49cc59a243f56557",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:26:47.418741Z",
     "start_time": "2024-08-02T12:17:08.888433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorboard.errors import InvalidArgumentError\n",
    "\n",
    "bar = LoadingBar(\n",
    "    len(param_grid['base_model']) * len(param_grid['lr']) * len(param_grid['fine_tune']) * len(param_grid['loss']) * len(param_grid['top'])\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for base_model in param_grid['base_model']:\n",
    "    for lr in param_grid['lr']:\n",
    "        for fine_tune in param_grid['fine_tune']:\n",
    "            for loss in param_grid['loss']:\n",
    "                for top in param_grid['top']:\n",
    "                    print(f'{c.OKGREEN}Model: {base_model} - LR: {lr} - Fine Tune: {fine_tune} - Loss: {loss} - Top: {top}{c.ENDC}')\n",
    "                    \n",
    "                    try:\n",
    "                        model = CNN(\n",
    "                            base=base_models[base_model],\n",
    "                            n_classes=3,\n",
    "                            input_shape=INPUT_SHAPE,\n",
    "                            fine_tune=fine_tune\n",
    "                        )\n",
    "                        model.build_top(activation='softmax', b_type=top)\n",
    "                        model.compile(lr=lr, loss=loss)\n",
    "                        model.fit(\n",
    "                            train_generator,\n",
    "                            val_generator,\n",
    "                            epochs=100,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            save=False,\n",
    "                            verbose=1\n",
    "                        )\n",
    "    \n",
    "                        results[\n",
    "                            str((base_model, lr, fine_tune, loss.__name__, top))\n",
    "                        ] = model.model.history.history\n",
    "                    except Exception as e:\n",
    "                        print(f'{c.FAIL}Error: {e}{c.ENDC}')\n",
    "                        results[(base_model, lr, fine_tune, loss, top)] = None\n",
    "\n",
    "                    clear_session()\n",
    "                    bar.update()\n",
    "                    \n",
    "    with open(f'../cell_division/results/{base_model}.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    results = {}\n",
    "\n",
    "bar.end()"
   ],
   "id": "52c645a63e00890e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: True - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 39s 2s/step - loss: 0.2121 - auc: 0.6865 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 11s 957ms/step - loss: 0.0492 - auc: 0.8214 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0400 - auc: 0.8783 - val_loss: 2.3649 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0298 - auc: 0.9291\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0298 - auc: 0.9291 - val_loss: 1.7135 - val_auc: 0.6797 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0244 - auc: 0.9563 - val_loss: 0.5383 - val_auc: 0.7284 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0216 - auc: 0.9634 - val_loss: 0.1094 - val_auc: 0.7475 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0197 - auc: 0.9682\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0197 - auc: 0.9682 - val_loss: 0.0556 - val_auc: 0.7342 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0186 - auc: 0.9713 - val_loss: 0.0644 - val_auc: 0.6516 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0184 - auc: 0.9719 - val_loss: 0.0727 - val_auc: 0.5849 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0183 - auc: 0.9723 - val_loss: 0.0805 - val_auc: 0.5476 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0181 - auc: 0.9730Restoring model weights from the end of the best epoch: 6.\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0181 - auc: 0.9730 - val_loss: 0.0883 - val_auc: 0.5262 - lr: 1.0000e-05\n",
      "Epoch 11: early stopping\n",
      "[                                                  ] 0.78%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: True - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 25s 1s/step - loss: 0.2922 - auc: 0.6331 - val_loss: 0.2252 - val_auc: 0.5925 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1827 - auc: 0.7454 - val_loss: 0.7076 - val_auc: 0.6851 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1341 - auc: 0.8071 - val_loss: 3.4205 - val_auc: 0.4241 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1027 - auc: 0.8298 - val_loss: 1.3354 - val_auc: 0.6463 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0586 - auc: 0.8897 - val_loss: 1.8079 - val_auc: 0.6166 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0561 - auc: 0.9198 - val_loss: 2.9644 - val_auc: 0.3489 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0511 - auc: 0.9201Restoring model weights from the end of the best epoch: 2.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0511 - auc: 0.9201 - val_loss: 4.0410 - val_auc: 0.3917 - lr: 0.0010\n",
      "Epoch 7: early stopping\n",
      "[                                                  ] 1.56%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: True - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 24s 1s/step - loss: 1.0148 - auc: 0.7026 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[=                                                 ] 2.34%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: True - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 25s 1s/step - loss: 1.0380 - auc: 0.7123 - val_loss: 1.2232 - val_auc: 0.4273 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9635 - auc: 0.8029 - val_loss: 1.0668 - val_auc: 0.6559 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9180 - auc: 0.8527 - val_loss: 1.0361 - val_auc: 0.6812 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8817 - auc: 0.8981\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.8817 - auc: 0.8981 - val_loss: 1.0795 - val_auc: 0.6659 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8690 - auc: 0.9019 - val_loss: 1.0639 - val_auc: 0.6595 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.8543 - auc: 0.9140 - val_loss: 1.0530 - val_auc: 0.6674 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8474 - auc: 0.9242\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.8474 - auc: 0.9242 - val_loss: 1.0822 - val_auc: 0.6205 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8403 - auc: 0.9299Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8403 - auc: 0.9299 - val_loss: 1.1221 - val_auc: 0.5565 - lr: 1.0000e-05\n",
      "Epoch 8: early stopping\n",
      "[=                                                 ] 3.12%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: False - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1279 - auc: 0.6664 - val_loss: 0.0936 - val_auc: 0.7190 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0649 - auc: 0.7429 - val_loss: 0.0572 - val_auc: 0.7331 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0505 - auc: 0.8028 - val_loss: 0.0518 - val_auc: 0.7937 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0450 - auc: 0.8587\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0450 - auc: 0.8587 - val_loss: 0.0489 - val_auc: 0.8250 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0423 - auc: 0.8960 - val_loss: 0.0485 - val_auc: 0.8236 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0412 - auc: 0.8934 - val_loss: 0.0493 - val_auc: 0.8180 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0408 - auc: 0.8954\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0408 - auc: 0.8954 - val_loss: 0.0482 - val_auc: 0.8272 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0404 - auc: 0.9017 - val_loss: 0.0482 - val_auc: 0.8273 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0403 - auc: 0.9019 - val_loss: 0.0482 - val_auc: 0.8267 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0403 - auc: 0.9016\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0403 - auc: 0.9016 - val_loss: 0.0482 - val_auc: 0.8267 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0402 - auc: 0.9017 - val_loss: 0.0482 - val_auc: 0.8268 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0402 - auc: 0.9017 - val_loss: 0.0482 - val_auc: 0.8267 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0402 - auc: 0.9017Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0402 - auc: 0.9017 - val_loss: 0.0482 - val_auc: 0.8266 - lr: 1.0000e-06\n",
      "Epoch 13: early stopping\n",
      "[=                                                 ] 3.91%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: False - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 22s 1s/step - loss: 0.2225 - auc: 0.6376 - val_loss: 0.0652 - val_auc: 0.7378 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.1402 - auc: 0.7979 - val_loss: 0.0567 - val_auc: 0.7963 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0958 - auc: 0.8531 - val_loss: 0.0889 - val_auc: 0.7926 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0671 - auc: 0.9008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0671 - auc: 0.9008 - val_loss: 0.0826 - val_auc: 0.7879 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0522 - auc: 0.9259 - val_loss: 0.0826 - val_auc: 0.8016 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.0463 - auc: 0.9335 - val_loss: 0.0889 - val_auc: 0.8098 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0508 - auc: 0.9255\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0508 - auc: 0.9255 - val_loss: 0.0934 - val_auc: 0.8101 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0464 - auc: 0.9362 - val_loss: 0.0880 - val_auc: 0.8127 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0485 - auc: 0.9352 - val_loss: 0.0825 - val_auc: 0.8161 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0468 - auc: 0.9366\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0468 - auc: 0.9366 - val_loss: 0.0777 - val_auc: 0.8197 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0475 - auc: 0.9368 - val_loss: 0.0746 - val_auc: 0.8228 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0433 - auc: 0.9381 - val_loss: 0.0720 - val_auc: 0.8251 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0526 - auc: 0.9277\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0526 - auc: 0.9277 - val_loss: 0.0698 - val_auc: 0.8282 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0479 - auc: 0.9346 - val_loss: 0.0681 - val_auc: 0.8303 - lr: 1.0000e-07\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0438 - auc: 0.9407 - val_loss: 0.0667 - val_auc: 0.8325 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0445 - auc: 0.9371\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0445 - auc: 0.9371 - val_loss: 0.0656 - val_auc: 0.8344 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0417 - auc: 0.9448 - val_loss: 0.0647 - val_auc: 0.8357 - lr: 1.0000e-08\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0495 - auc: 0.9339 - val_loss: 0.0641 - val_auc: 0.8364 - lr: 1.0000e-08\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0428 - auc: 0.9406\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0428 - auc: 0.9406 - val_loss: 0.0636 - val_auc: 0.8382 - lr: 1.0000e-08\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0494 - auc: 0.9307 - val_loss: 0.0633 - val_auc: 0.8393 - lr: 1.0000e-09\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0431 - auc: 0.9423 - val_loss: 0.0630 - val_auc: 0.8405 - lr: 1.0000e-09\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0427 - auc: 0.9371\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0427 - auc: 0.9371 - val_loss: 0.0629 - val_auc: 0.8417 - lr: 1.0000e-09\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0414 - auc: 0.9445 - val_loss: 0.0629 - val_auc: 0.8424 - lr: 1.0000e-10\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0456 - auc: 0.9401 - val_loss: 0.0630 - val_auc: 0.8433 - lr: 1.0000e-10\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0422 - auc: 0.9418\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0422 - auc: 0.9418 - val_loss: 0.0631 - val_auc: 0.8441 - lr: 1.0000e-10\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0473 - auc: 0.9347 - val_loss: 0.0633 - val_auc: 0.8455 - lr: 1.0000e-11\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.0496 - auc: 0.9332 - val_loss: 0.0635 - val_auc: 0.8455 - lr: 1.0000e-11\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0462 - auc: 0.9401\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0462 - auc: 0.9401 - val_loss: 0.0637 - val_auc: 0.8463 - lr: 1.0000e-11\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0406 - auc: 0.9439 - val_loss: 0.0640 - val_auc: 0.8467 - lr: 1.0000e-12\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.0422 - auc: 0.9411 - val_loss: 0.0642 - val_auc: 0.8468 - lr: 1.0000e-12\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0458 - auc: 0.9412\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0458 - auc: 0.9412 - val_loss: 0.0645 - val_auc: 0.8471 - lr: 1.0000e-12\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0449 - auc: 0.9408 - val_loss: 0.0648 - val_auc: 0.8472 - lr: 1.0000e-13\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0460 - auc: 0.9353 - val_loss: 0.0651 - val_auc: 0.8476 - lr: 1.0000e-13\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0387 - auc: 0.9447\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0387 - auc: 0.9447 - val_loss: 0.0654 - val_auc: 0.8475 - lr: 1.0000e-13\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0407 - auc: 0.9458 - val_loss: 0.0657 - val_auc: 0.8480 - lr: 1.0000e-14\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0438 - auc: 0.9365 - val_loss: 0.0659 - val_auc: 0.8483 - lr: 1.0000e-14\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0415 - auc: 0.9425\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0415 - auc: 0.9425 - val_loss: 0.0662 - val_auc: 0.8487 - lr: 1.0000e-14\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0436 - auc: 0.9363 - val_loss: 0.0665 - val_auc: 0.8491 - lr: 1.0000e-15\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0448 - auc: 0.9384 - val_loss: 0.0668 - val_auc: 0.8491 - lr: 1.0000e-15\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0507 - auc: 0.9270\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0507 - auc: 0.9270 - val_loss: 0.0670 - val_auc: 0.8493 - lr: 1.0000e-15\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0422 - auc: 0.9391 - val_loss: 0.0673 - val_auc: 0.8495 - lr: 1.0000e-16\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0457 - auc: 0.9378 - val_loss: 0.0675 - val_auc: 0.8496 - lr: 1.0000e-16\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0444 - auc: 0.9384\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0444 - auc: 0.9384 - val_loss: 0.0677 - val_auc: 0.8496 - lr: 1.0000e-16\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0458 - auc: 0.9378 - val_loss: 0.0679 - val_auc: 0.8497 - lr: 1.0000e-17\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0421 - auc: 0.9401 - val_loss: 0.0681 - val_auc: 0.8501 - lr: 1.0000e-17\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0424 - auc: 0.9413\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0424 - auc: 0.9413 - val_loss: 0.0683 - val_auc: 0.8504 - lr: 1.0000e-17\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0438 - auc: 0.9406 - val_loss: 0.0685 - val_auc: 0.8508 - lr: 1.0000e-18\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0416 - auc: 0.9449 - val_loss: 0.0687 - val_auc: 0.8507 - lr: 1.0000e-18\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0425 - auc: 0.9428\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0425 - auc: 0.9428 - val_loss: 0.0688 - val_auc: 0.8504 - lr: 1.0000e-18\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0461 - auc: 0.9352 - val_loss: 0.0690 - val_auc: 0.8507 - lr: 1.0000e-19\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0469 - auc: 0.9376 - val_loss: 0.0691 - val_auc: 0.8506 - lr: 1.0000e-19\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0427 - auc: 0.9387Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.0427 - auc: 0.9387 - val_loss: 0.0692 - val_auc: 0.8508 - lr: 1.0000e-19\n",
      "Epoch 52: early stopping\n",
      "[==                                                ] 4.69%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: False - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 21s 1s/step - loss: 1.0232 - auc: 0.6919 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-04\n",
      "Epoch 6: early stopping\n",
      "[==                                                ] 5.47%\u001B[92mModel: DenseNet121 - LR: 0.001 - Fine Tune: False - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 21s 1s/step - loss: 1.0692 - auc: 0.6570 - val_loss: 1.1040 - val_auc: 0.5853 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9841 - auc: 0.7829 - val_loss: 1.0772 - val_auc: 0.6481 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9477 - auc: 0.8312 - val_loss: 1.0582 - val_auc: 0.7000 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9265 - auc: 0.8599\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9265 - auc: 0.8599 - val_loss: 1.0465 - val_auc: 0.7290 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9099 - auc: 0.8807 - val_loss: 1.0413 - val_auc: 0.7401 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9047 - auc: 0.8885 - val_loss: 1.0356 - val_auc: 0.7520 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9008 - auc: 0.8930\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9008 - auc: 0.8930 - val_loss: 1.0332 - val_auc: 0.7562 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9026 - auc: 0.8880 - val_loss: 1.0322 - val_auc: 0.7586 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8984 - auc: 0.8947 - val_loss: 1.0311 - val_auc: 0.7605 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8989 - auc: 0.8972\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8989 - auc: 0.8972 - val_loss: 1.0298 - val_auc: 0.7633 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9004 - auc: 0.8941 - val_loss: 1.0283 - val_auc: 0.7661 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8965 - auc: 0.8958 - val_loss: 1.0267 - val_auc: 0.7674 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8983 - auc: 0.8957\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8983 - auc: 0.8957 - val_loss: 1.0250 - val_auc: 0.7691 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8949 - auc: 0.8921 - val_loss: 1.0233 - val_auc: 0.7702 - lr: 1.0000e-07\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9010 - auc: 0.8963 - val_loss: 1.0217 - val_auc: 0.7712 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8984 - auc: 0.8955\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8984 - auc: 0.8955 - val_loss: 1.0200 - val_auc: 0.7718 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8978 - auc: 0.8948 - val_loss: 1.0185 - val_auc: 0.7716 - lr: 1.0000e-08\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8983 - auc: 0.8941 - val_loss: 1.0170 - val_auc: 0.7722 - lr: 1.0000e-08\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9026 - auc: 0.8919\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.9026 - auc: 0.8919 - val_loss: 1.0156 - val_auc: 0.7721 - lr: 1.0000e-08\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9061 - auc: 0.8860 - val_loss: 1.0143 - val_auc: 0.7722 - lr: 1.0000e-09\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8958 - auc: 0.8969 - val_loss: 1.0131 - val_auc: 0.7726 - lr: 1.0000e-09\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8950 - auc: 0.8951\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8950 - auc: 0.8951 - val_loss: 1.0120 - val_auc: 0.7732 - lr: 1.0000e-09\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8960 - auc: 0.8982 - val_loss: 1.0110 - val_auc: 0.7733 - lr: 1.0000e-10\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9020 - auc: 0.8909 - val_loss: 1.0101 - val_auc: 0.7729 - lr: 1.0000e-10\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8973 - auc: 0.8980\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8973 - auc: 0.8980 - val_loss: 1.0093 - val_auc: 0.7727 - lr: 1.0000e-10\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8983 - auc: 0.8917 - val_loss: 1.0086 - val_auc: 0.7734 - lr: 1.0000e-11\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.8980 - auc: 0.8958 - val_loss: 1.0080 - val_auc: 0.7738 - lr: 1.0000e-11\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8934 - auc: 0.8963\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8934 - auc: 0.8963 - val_loss: 1.0074 - val_auc: 0.7744 - lr: 1.0000e-11\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8996 - auc: 0.8947 - val_loss: 1.0070 - val_auc: 0.7741 - lr: 1.0000e-12\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8970 - auc: 0.8991 - val_loss: 1.0065 - val_auc: 0.7732 - lr: 1.0000e-12\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8987 - auc: 0.8937\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.8987 - auc: 0.8937 - val_loss: 1.0062 - val_auc: 0.7735 - lr: 1.0000e-12\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.8946 - auc: 0.8963 - val_loss: 1.0058 - val_auc: 0.7730 - lr: 1.0000e-13\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8979 - auc: 0.8930Restoring model weights from the end of the best epoch: 28.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.8979 - auc: 0.8930 - val_loss: 1.0055 - val_auc: 0.7733 - lr: 1.0000e-13\n",
      "Epoch 33: early stopping\n",
      "[===                                               ] 6.25%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: True - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 26s 1s/step - loss: 2.0587 - auc: 0.6812 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1259 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 2.1259 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 2.1259 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 2.1259 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2.1260 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 2.1259 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2.1259 - auc: 0.7008 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[===                                               ] 7.03%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: True - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 26s 1s/step - loss: 0.2763 - auc: 0.5975 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0813 - auc: 0.7208 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0681 - auc: 0.7237 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0719 - auc: 0.7254\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0719 - auc: 0.7254 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0593 - auc: 0.7951 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0545 - auc: 0.8289Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0545 - auc: 0.8289 - val_loss: 2.4222 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[===                                               ] 7.81%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: True - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 27s 1s/step - loss: 1.0207 - auc: 0.6971 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[====                                              ] 8.59%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: True - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 25s 1s/step - loss: 1.0132 - auc: 0.7336 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9744 - auc: 0.7558 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9676 - auc: 0.7650 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9878 - auc: 0.7412\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9878 - auc: 0.7412 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9709 - auc: 0.7578 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9704 - auc: 0.7548Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9704 - auc: 0.7548 - val_loss: 1.2233 - val_auc: 0.4273 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[====                                              ] 9.38%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: False - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 21s 1s/step - loss: 1.4944 - auc: 0.6844 - val_loss: 1.6630 - val_auc: 0.4743 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.7337 - auc: 0.6593 - val_loss: 0.4681 - val_auc: 0.6097 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.2371 - auc: 0.7080 - val_loss: 0.1277 - val_auc: 0.7245 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0796 - auc: 0.7645\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0796 - auc: 0.7645 - val_loss: 0.0626 - val_auc: 0.7446 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0478 - auc: 0.8336 - val_loss: 0.0557 - val_auc: 0.7587 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0443 - auc: 0.8680 - val_loss: 0.0537 - val_auc: 0.7665 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0418 - auc: 0.8806\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0418 - auc: 0.8806 - val_loss: 0.0536 - val_auc: 0.7736 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0410 - auc: 0.8848 - val_loss: 0.0534 - val_auc: 0.7745 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0409 - auc: 0.8866 - val_loss: 0.0531 - val_auc: 0.7766 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0407 - auc: 0.8886\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0407 - auc: 0.8886 - val_loss: 0.0529 - val_auc: 0.7780 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0407 - auc: 0.8898 - val_loss: 0.0528 - val_auc: 0.7783 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0407 - auc: 0.8898 - val_loss: 0.0528 - val_auc: 0.7784 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0406 - auc: 0.8900\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0406 - auc: 0.8900 - val_loss: 0.0528 - val_auc: 0.7785 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0406 - auc: 0.8901 - val_loss: 0.0528 - val_auc: 0.7785 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0406 - auc: 0.8901 - val_loss: 0.0528 - val_auc: 0.7785 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0406 - auc: 0.8901\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0406 - auc: 0.8901 - val_loss: 0.0528 - val_auc: 0.7785 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0406 - auc: 0.8901 - val_loss: 0.0528 - val_auc: 0.7785 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0406 - auc: 0.8901Restoring model weights from the end of the best epoch: 13.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0406 - auc: 0.8901 - val_loss: 0.0528 - val_auc: 0.7785 - lr: 1.0000e-07\n",
      "Epoch 18: early stopping\n",
      "[=====                                             ] 10.16%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: False - Loss: <function focal_loss.<locals>.focal_loss_fixed at 0x7709b2018820> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 20s 1s/step - loss: 0.5149 - auc: 0.6359 - val_loss: 0.7676 - val_auc: 0.5256 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1516 - auc: 0.7761 - val_loss: 0.6623 - val_auc: 0.6853 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.1245 - auc: 0.7778 - val_loss: 0.2215 - val_auc: 0.7871 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1011 - auc: 0.8377\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.1011 - auc: 0.8377 - val_loss: 0.5352 - val_auc: 0.7337 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0637 - auc: 0.8672 - val_loss: 0.1421 - val_auc: 0.8022 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0598 - auc: 0.8875 - val_loss: 0.1913 - val_auc: 0.7968 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0742 - auc: 0.8630\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0742 - auc: 0.8630 - val_loss: 0.1211 - val_auc: 0.8087 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0633 - auc: 0.8825 - val_loss: 0.1128 - val_auc: 0.8143 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0690 - auc: 0.8831 - val_loss: 0.1090 - val_auc: 0.8171 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0573 - auc: 0.8913\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0573 - auc: 0.8913 - val_loss: 0.1027 - val_auc: 0.8187 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.0594 - auc: 0.8909 - val_loss: 0.0945 - val_auc: 0.8223 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0637 - auc: 0.8934 - val_loss: 0.0881 - val_auc: 0.8241 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0583 - auc: 0.8896\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0583 - auc: 0.8896 - val_loss: 0.0829 - val_auc: 0.8261 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0517 - auc: 0.9051 - val_loss: 0.0789 - val_auc: 0.8273 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0564 - auc: 0.8903 - val_loss: 0.0758 - val_auc: 0.8289 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0584 - auc: 0.8902\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.0584 - auc: 0.8902 - val_loss: 0.0732 - val_auc: 0.8302 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0627 - auc: 0.8819 - val_loss: 0.0711 - val_auc: 0.8315 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0626 - auc: 0.8818 - val_loss: 0.0694 - val_auc: 0.8321 - lr: 1.0000e-07\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0500 - auc: 0.8999\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0500 - auc: 0.8999 - val_loss: 0.0680 - val_auc: 0.8328 - lr: 1.0000e-07\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0520 - auc: 0.8997 - val_loss: 0.0668 - val_auc: 0.8334 - lr: 1.0000e-08\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0622 - auc: 0.8838 - val_loss: 0.0658 - val_auc: 0.8346 - lr: 1.0000e-08\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0577 - auc: 0.8961\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0577 - auc: 0.8961 - val_loss: 0.0650 - val_auc: 0.8349 - lr: 1.0000e-08\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0600 - auc: 0.8915 - val_loss: 0.0643 - val_auc: 0.8353 - lr: 1.0000e-09\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0557 - auc: 0.8915 - val_loss: 0.0637 - val_auc: 0.8355 - lr: 1.0000e-09\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0550 - auc: 0.8952\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0550 - auc: 0.8952 - val_loss: 0.0632 - val_auc: 0.8357 - lr: 1.0000e-09\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0574 - auc: 0.8933 - val_loss: 0.0627 - val_auc: 0.8362 - lr: 1.0000e-10\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0620 - auc: 0.8813 - val_loss: 0.0624 - val_auc: 0.8365 - lr: 1.0000e-10\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0555 - auc: 0.8907\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0555 - auc: 0.8907 - val_loss: 0.0620 - val_auc: 0.8365 - lr: 1.0000e-10\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0583 - auc: 0.8894 - val_loss: 0.0618 - val_auc: 0.8371 - lr: 1.0000e-11\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0528 - auc: 0.8983 - val_loss: 0.0615 - val_auc: 0.8375 - lr: 1.0000e-11\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0587 - auc: 0.8872\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0587 - auc: 0.8872 - val_loss: 0.0613 - val_auc: 0.8374 - lr: 1.0000e-11\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0651 - auc: 0.8814 - val_loss: 0.0611 - val_auc: 0.8375 - lr: 1.0000e-12\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0631 - auc: 0.8928 - val_loss: 0.0610 - val_auc: 0.8377 - lr: 1.0000e-12\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0600 - auc: 0.8907\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0600 - auc: 0.8907 - val_loss: 0.0608 - val_auc: 0.8377 - lr: 1.0000e-12\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0546 - auc: 0.8919 - val_loss: 0.0607 - val_auc: 0.8379 - lr: 1.0000e-13\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0544 - auc: 0.8969 - val_loss: 0.0606 - val_auc: 0.8379 - lr: 1.0000e-13\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0581 - auc: 0.8933\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0581 - auc: 0.8933 - val_loss: 0.0605 - val_auc: 0.8378 - lr: 1.0000e-13\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0553 - auc: 0.8929 - val_loss: 0.0604 - val_auc: 0.8377 - lr: 1.0000e-14\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0562 - auc: 0.8944 - val_loss: 0.0604 - val_auc: 0.8378 - lr: 1.0000e-14\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0497 - auc: 0.9057\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0497 - auc: 0.9057 - val_loss: 0.0603 - val_auc: 0.8380 - lr: 1.0000e-14\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0575 - auc: 0.8907 - val_loss: 0.0603 - val_auc: 0.8383 - lr: 1.0000e-15\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0526 - auc: 0.9033 - val_loss: 0.0602 - val_auc: 0.8382 - lr: 1.0000e-15\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0542 - auc: 0.9010\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0542 - auc: 0.9010 - val_loss: 0.0602 - val_auc: 0.8383 - lr: 1.0000e-15\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0562 - auc: 0.8928 - val_loss: 0.0601 - val_auc: 0.8381 - lr: 1.0000e-16\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0645 - auc: 0.8820 - val_loss: 0.0601 - val_auc: 0.8383 - lr: 1.0000e-16\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0535 - auc: 0.8954\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0535 - auc: 0.8954 - val_loss: 0.0601 - val_auc: 0.8384 - lr: 1.0000e-16\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0574 - auc: 0.8848 - val_loss: 0.0601 - val_auc: 0.8383 - lr: 1.0000e-17\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0603 - auc: 0.8832 - val_loss: 0.0600 - val_auc: 0.8383 - lr: 1.0000e-17\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0644 - auc: 0.8900\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0644 - auc: 0.8900 - val_loss: 0.0600 - val_auc: 0.8385 - lr: 1.0000e-17\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0538 - auc: 0.8959 - val_loss: 0.0600 - val_auc: 0.8385 - lr: 1.0000e-18\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0571 - auc: 0.8904 - val_loss: 0.0600 - val_auc: 0.8386 - lr: 1.0000e-18\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0519 - auc: 0.9010\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 9.999999424161285e-20.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0519 - auc: 0.9010 - val_loss: 0.0600 - val_auc: 0.8386 - lr: 1.0000e-18\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0533 - auc: 0.9028 - val_loss: 0.0599 - val_auc: 0.8386 - lr: 1.0000e-19\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0634 - auc: 0.8801 - val_loss: 0.0599 - val_auc: 0.8386 - lr: 1.0000e-19\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0624 - auc: 0.8906\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-21.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0624 - auc: 0.8906 - val_loss: 0.0599 - val_auc: 0.8387 - lr: 1.0000e-19\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0486 - auc: 0.9029 - val_loss: 0.0599 - val_auc: 0.8388 - lr: 1.0000e-20\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0569 - auc: 0.8923 - val_loss: 0.0599 - val_auc: 0.8389 - lr: 1.0000e-20\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0610 - auc: 0.8814\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-22.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0610 - auc: 0.8814 - val_loss: 0.0599 - val_auc: 0.8388 - lr: 1.0000e-20\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0580 - auc: 0.8852 - val_loss: 0.0599 - val_auc: 0.8389 - lr: 1.0000e-21\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0609 - auc: 0.8905 - val_loss: 0.0599 - val_auc: 0.8389 - lr: 1.0000e-21\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0607 - auc: 0.8819\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-23.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0607 - auc: 0.8819 - val_loss: 0.0599 - val_auc: 0.8390 - lr: 1.0000e-21\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0608 - auc: 0.8932 - val_loss: 0.0599 - val_auc: 0.8391 - lr: 1.0000e-22\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0563 - auc: 0.8975 - val_loss: 0.0599 - val_auc: 0.8392 - lr: 1.0000e-22\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0493 - auc: 0.9096\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.999999682655227e-24.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0493 - auc: 0.9096 - val_loss: 0.0599 - val_auc: 0.8392 - lr: 1.0000e-22\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0596 - auc: 0.8901 - val_loss: 0.0599 - val_auc: 0.8391 - lr: 1.0000e-23\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.0590 - auc: 0.8889 - val_loss: 0.0599 - val_auc: 0.8391 - lr: 1.0000e-23\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0561 - auc: 0.8947\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 9.999999998199588e-25.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0561 - auc: 0.8947 - val_loss: 0.0599 - val_auc: 0.8391 - lr: 1.0000e-23\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0589 - auc: 0.8960Restoring model weights from the end of the best epoch: 63.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0589 - auc: 0.8960 - val_loss: 0.0599 - val_auc: 0.8391 - lr: 1.0000e-24\n",
      "Epoch 68: early stopping\n",
      "[=====                                             ] 10.94%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: False - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: CAM\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 22s 1s/step - loss: 1.0198 - auc: 0.6981 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0094 - auc: 0.7008Restoring model weights from the end of the best epoch: 1.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0094 - auc: 0.7008 - val_loss: 1.0420 - val_auc: 0.6591 - lr: 1.0000e-03\n",
      "Epoch 6: early stopping\n",
      "[=====                                             ] 11.72%\u001B[92mModel: DenseNet121 - LR: 0.01 - Fine Tune: False - Loss: <function w_cel_loss.<locals>.weighted_cross_entropy_with_logits at 0x7709b20183a0> - Top: Standard\u001B[0m\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 21s 1s/step - loss: 1.0514 - auc: 0.6783 - val_loss: 1.1718 - val_auc: 0.4756 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0139 - auc: 0.7108 - val_loss: 1.1132 - val_auc: 0.5767 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9821 - auc: 0.7611 - val_loss: 1.0568 - val_auc: 0.6494 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9636 - auc: 0.7763\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9636 - auc: 0.7763 - val_loss: 1.0744 - val_auc: 0.6250 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9511 - auc: 0.7951 - val_loss: 1.0661 - val_auc: 0.6420 - lr: 1.0000e-03\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9469 - auc: 0.8031 - val_loss: 1.0612 - val_auc: 0.6612 - lr: 1.0000e-03\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9420 - auc: 0.8062\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9420 - auc: 0.8062 - val_loss: 1.0514 - val_auc: 0.6639 - lr: 1.0000e-03\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9405 - auc: 0.8034 - val_loss: 1.0468 - val_auc: 0.6655 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9446 - auc: 0.8046 - val_loss: 1.0425 - val_auc: 0.6769 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9370 - auc: 0.8087\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9370 - auc: 0.8087 - val_loss: 1.0388 - val_auc: 0.6833 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9392 - auc: 0.8050 - val_loss: 1.0355 - val_auc: 0.6888 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9385 - auc: 0.8106 - val_loss: 1.0311 - val_auc: 0.7013 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9407 - auc: 0.8070\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.9407 - auc: 0.8070 - val_loss: 1.0265 - val_auc: 0.7049 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 11s 950ms/step - loss: 0.9358 - auc: 0.8120 - val_loss: 1.0220 - val_auc: 0.7089 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 11s 963ms/step - loss: 0.9351 - auc: 0.8133 - val_loss: 1.0179 - val_auc: 0.7105 - lr: 1.0000e-06\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9365 - auc: 0.8124\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9365 - auc: 0.8124 - val_loss: 1.0143 - val_auc: 0.7127 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9369 - auc: 0.8067 - val_loss: 1.0111 - val_auc: 0.7236 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9388 - auc: 0.8080 - val_loss: 1.0082 - val_auc: 0.7264 - lr: 1.0000e-07\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9400 - auc: 0.8078\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "12/12 [==============================] - 11s 950ms/step - loss: 0.9400 - auc: 0.8078 - val_loss: 1.0056 - val_auc: 0.7308 - lr: 1.0000e-07\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 11s 948ms/step - loss: 0.9411 - auc: 0.8129 - val_loss: 1.0033 - val_auc: 0.7381 - lr: 1.0000e-08\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9369 - auc: 0.8094 - val_loss: 1.0013 - val_auc: 0.7436 - lr: 1.0000e-08\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9407 - auc: 0.8077\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.9407 - auc: 0.8077 - val_loss: 0.9995 - val_auc: 0.7465 - lr: 1.0000e-08\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9380 - auc: 0.8054 - val_loss: 0.9979 - val_auc: 0.7472 - lr: 1.0000e-09\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 11s 944ms/step - loss: 0.9356 - auc: 0.8085 - val_loss: 0.9965 - val_auc: 0.7501 - lr: 1.0000e-09\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9382 - auc: 0.8125\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "12/12 [==============================] - 11s 955ms/step - loss: 0.9382 - auc: 0.8125 - val_loss: 0.9953 - val_auc: 0.7501 - lr: 1.0000e-09\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 11s 972ms/step - loss: 0.9411 - auc: 0.8085 - val_loss: 0.9942 - val_auc: 0.7511 - lr: 1.0000e-10\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 11s 955ms/step - loss: 0.9386 - auc: 0.8103 - val_loss: 0.9933 - val_auc: 0.7526 - lr: 1.0000e-10\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9366 - auc: 0.8149\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "12/12 [==============================] - 11s 976ms/step - loss: 0.9366 - auc: 0.8149 - val_loss: 0.9924 - val_auc: 0.7525 - lr: 1.0000e-10\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 11s 952ms/step - loss: 0.9387 - auc: 0.8110 - val_loss: 0.9917 - val_auc: 0.7528 - lr: 1.0000e-11\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 11s 911ms/step - loss: 0.9368 - auc: 0.8128 - val_loss: 0.9910 - val_auc: 0.7522 - lr: 1.0000e-11\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9380 - auc: 0.8137\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "12/12 [==============================] - 11s 943ms/step - loss: 0.9380 - auc: 0.8137 - val_loss: 0.9904 - val_auc: 0.7523 - lr: 1.0000e-11\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9391 - auc: 0.8128 - val_loss: 0.9898 - val_auc: 0.7522 - lr: 1.0000e-12\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9398 - auc: 0.8075 - val_loss: 0.9894 - val_auc: 0.7516 - lr: 1.0000e-12\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9403 - auc: 0.8058Restoring model weights from the end of the best epoch: 29.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.9403 - auc: 0.8058 - val_loss: 0.9889 - val_auc: 0.7517 - lr: 1.0000e-12\n",
      "Epoch 34: early stopping\n",
      "[======                                            ] 12.50%"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type History is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 45\u001B[0m\n\u001B[1;32m     42\u001B[0m                     bar\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../cell_division/results/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_model\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 45\u001B[0m         \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m     results \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     48\u001B[0m bar\u001B[38;5;241m.\u001B[39mend()\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/json/__init__.py:179\u001B[0m, in \u001B[0;36mdump\u001B[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[0m\n\u001B[1;32m    173\u001B[0m     iterable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(skipkeys\u001B[38;5;241m=\u001B[39mskipkeys, ensure_ascii\u001B[38;5;241m=\u001B[39mensure_ascii,\n\u001B[1;32m    174\u001B[0m         check_circular\u001B[38;5;241m=\u001B[39mcheck_circular, allow_nan\u001B[38;5;241m=\u001B[39mallow_nan, indent\u001B[38;5;241m=\u001B[39mindent,\n\u001B[1;32m    175\u001B[0m         separators\u001B[38;5;241m=\u001B[39mseparators,\n\u001B[1;32m    176\u001B[0m         default\u001B[38;5;241m=\u001B[39mdefault, sort_keys\u001B[38;5;241m=\u001B[39msort_keys, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\u001B[38;5;241m.\u001B[39miterencode(obj)\n\u001B[1;32m    177\u001B[0m \u001B[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# a debuggability cost\u001B[39;00m\n\u001B[0;32m--> 179\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m    180\u001B[0m     fp\u001B[38;5;241m.\u001B[39mwrite(chunk)\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/json/encoder.py:431\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode\u001B[0;34m(o, _current_indent_level)\u001B[0m\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_list(o, _current_indent_level)\n\u001B[1;32m    430\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m--> 431\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_dict(o, _current_indent_level)\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    433\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/json/encoder.py:405\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode_dict\u001B[0;34m(dct, _current_indent_level)\u001B[0m\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    404\u001B[0m             chunks \u001B[38;5;241m=\u001B[39m _iterencode(value, _current_indent_level)\n\u001B[0;32m--> 405\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m chunks\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m newline_indent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    407\u001B[0m     _current_indent_level \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/json/encoder.py:438\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode\u001B[0;34m(o, _current_indent_level)\u001B[0m\n\u001B[1;32m    436\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCircular reference detected\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    437\u001B[0m     markers[markerid] \u001B[38;5;241m=\u001B[39m o\n\u001B[0;32m--> 438\u001B[0m o \u001B[38;5;241m=\u001B[39m \u001B[43m_default\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m _iterencode(o, _current_indent_level)\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/json/encoder.py:179\u001B[0m, in \u001B[0;36mJSONEncoder.default\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault\u001B[39m(\u001B[38;5;28mself\u001B[39m, o):\n\u001B[1;32m    161\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    (to raise a ``TypeError``).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    177\u001B[0m \n\u001B[1;32m    178\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mObject of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mo\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    180\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis not JSON serializable\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Object of type History is not JSON serializable"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(json.dumps(results, indent=4))\n",
    "# Save\n",
    "with open('../cell_division/results/grid_search_cnn.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "id": "87db1c7a4b035978",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
