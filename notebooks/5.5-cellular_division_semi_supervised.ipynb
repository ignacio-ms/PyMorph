{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:26:11.570660Z",
     "start_time": "2024-08-14T08:26:06.419630Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cell_division.nets.transfer_learning import CNN\n",
    "from auxiliary.data.dataset_cell import CellDataset\n",
    "from auxiliary.data.dataset_unlabeled import UnlabeledDataset\n",
    "from auxiliary import values as v\n",
    "from auxiliary.utils.colors import bcolors as c\n",
    "from auxiliary.utils import visualizer as vis\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from cell_division.nets.custom_layers import (\n",
    "    w_cel_loss, \n",
    "    focal_loss,\n",
    "    ExtendedLSEPooling,\n",
    "    extended_w_cel_loss,\n",
    "    LSEPooling\n",
    ")\n",
    "\n",
    "from cell_division.nets.cam import GradCAM, overlay_heatmap, CAM, GradCAMpp\n",
    "from cell_division.semi_supervised import semi_supervised_learning as SSL\n",
    "\n",
    "# GPU config\n",
    "from auxiliary.utils.timer import LoadingBar\n",
    "from auxiliary.gpu.gpu_tf import (\n",
    "    increase_gpu_memory, \n",
    "    set_gpu_allocator, \n",
    "    clear_session\n",
    ")\n",
    "\n",
    "increase_gpu_memory()\n",
    "# set_gpu_allocator()"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set memory growth on device when virtual devices configured",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 41\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauxiliary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtimer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoadingBar\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauxiliary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgpu\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgpu_tf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     36\u001B[0m     increase_gpu_memory, \n\u001B[1;32m     37\u001B[0m     set_gpu_allocator, \n\u001B[1;32m     38\u001B[0m     clear_session\n\u001B[1;32m     39\u001B[0m )\n\u001B[0;32m---> 41\u001B[0m \u001B[43mincrease_gpu_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# set_gpu_allocator()\u001B[39;00m\n",
      "File \u001B[0;32m~/ht_morphogenesis/auxiliary/gpu/gpu_tf.py:15\u001B[0m, in \u001B[0;36mincrease_gpu_memory\u001B[0;34m(limit)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m gpu \u001B[38;5;129;01min\u001B[39;00m gpus:\n\u001B[0;32m---> 15\u001B[0m         \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_memory_growth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgpu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m         tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mset_virtual_device_configuration(\n\u001B[1;32m     17\u001B[0m             gpu,\n\u001B[1;32m     18\u001B[0m             [tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mVirtualDeviceConfiguration(memory_limit\u001B[38;5;241m=\u001B[39mlimit)]\n\u001B[1;32m     19\u001B[0m         )\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/config.py:713\u001B[0m, in \u001B[0;36mset_memory_growth\u001B[0;34m(device, enable)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.experimental.set_memory_growth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_memory_growth\u001B[39m(device, enable):\n\u001B[1;32m    690\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001B[39;00m\n\u001B[1;32m    691\u001B[0m \n\u001B[1;32m    692\u001B[0m \u001B[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001B[39;00m\n\u001B[1;32m    712\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 713\u001B[0m   \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_memory_growth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1577\u001B[0m, in \u001B[0;36mContext.set_memory_growth\u001B[0;34m(self, dev, enable)\u001B[0m\n\u001B[1;32m   1574\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized device: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mrepr\u001B[39m(dev))\n\u001B[1;32m   1576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_virtual_device_map:\n\u001B[0;32m-> 1577\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1578\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot set memory growth on device when virtual devices configured\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev\u001B[38;5;241m.\u001B[39mdevice_type \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1581\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot set memory growth on non-GPU devices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot set memory growth on device when virtual devices configured"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T08:26:25.141600Z",
     "start_time": "2024-08-14T08:26:25.136247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = v.data_path + 'CellDivision/images_nuclei/'\n",
    "img_dir_unlabeled = v.data_path + 'CellDivision/images_unlabeled/'\n",
    "\n",
    "label_train_dir = v.data_path + 'CellDivision/undersampled/train.csv'\n",
    "label_test_dir = v.data_path + 'CellDivision/undersampled/test.csv'\n",
    "label_val_dir = v.data_path + 'CellDivision/undersampled/val.csv'\n",
    "\n",
    "INPUT_SHAPE = (100, 100, 3)\n",
    "BATCH_SIZE = 128"
   ],
   "id": "a1afd82f2525feb7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T08:26:32.030190Z",
     "start_time": "2024-08-14T08:26:28.484372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_train_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "val_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_val_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "test_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_test_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "unlabeled_generator = UnlabeledDataset(\n",
    "    img_dir_unlabeled,\n",
    "    batch_size=1,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")"
   ],
   "id": "64e98694d41986fe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T08:26:34.566228Z",
     "start_time": "2024-08-14T08:26:32.871084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    base=tf.keras.applications.VGG16,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    n_classes=3\n",
    ")\n",
    "model.build_top(activation='softmax', b_type='CAM', pooling=ExtendedLSEPooling)\n",
    "model.compile(\n",
    "    lr=.001,\n",
    "    loss=extended_w_cel_loss()\n",
    ")"
   ],
   "id": "3747c34497d9ef9e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T11:26:08.879115Z",
     "start_time": "2024-08-14T08:32:12.395875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SSL(\n",
    "    model, \n",
    "    train_generator, val_generator, test_generator,\n",
    "    unlabeled_generator,\n",
    "    max_iter=10,\n",
    "    verbose=1\n",
    ")\n",
    "model.model.save('../models/cellular_division_models/vgg16_semi.h5')"
   ],
   "id": "97d72a54693578ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mIteration:\u001B[0m 1\n",
      "\t\u001B[94mPre-training...\u001B[0m\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.5812 - auc: 0.9683 - val_loss: 1.0401 - val_auc: 0.8645 - lr: 1.0000e-06\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.8229 - auc: 0.9451 - val_loss: 1.0110 - val_auc: 0.8792 - lr: 1.0000e-06\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6857 - auc: 0.9632 - val_loss: 0.9820 - val_auc: 0.8948 - lr: 1.0000e-06\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7221 - auc: 0.9533\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "7/7 [==============================] - 16s 2s/step - loss: 0.7221 - auc: 0.9533 - val_loss: 0.9537 - val_auc: 0.9066 - lr: 1.0000e-06\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.7073 - auc: 0.9581 - val_loss: 0.9256 - val_auc: 0.9173 - lr: 1.0000e-07\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.5832 - auc: 0.9632 - val_loss: 0.8981 - val_auc: 0.9255 - lr: 1.0000e-07\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8113 - auc: 0.9533\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.8113 - auc: 0.9533 - val_loss: 0.8712 - val_auc: 0.9325 - lr: 1.0000e-07\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6215 - auc: 0.9664 - val_loss: 0.8449 - val_auc: 0.9383 - lr: 1.0000e-08\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6956 - auc: 0.9573 - val_loss: 0.8195 - val_auc: 0.9432 - lr: 1.0000e-08\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6821 - auc: 0.9618\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.6821 - auc: 0.9618 - val_loss: 0.7949 - val_auc: 0.9466 - lr: 1.0000e-08\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.7579 - auc: 0.9534 - val_loss: 0.7712 - val_auc: 0.9500 - lr: 1.0000e-09\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6317 - auc: 0.9632 - val_loss: 0.7486 - val_auc: 0.9522 - lr: 1.0000e-09\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7304 - auc: 0.9530\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.7304 - auc: 0.9530 - val_loss: 0.7270 - val_auc: 0.9543 - lr: 1.0000e-09\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6750 - auc: 0.9627 - val_loss: 0.7066 - val_auc: 0.9563 - lr: 1.0000e-10\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.5701 - auc: 0.9636 - val_loss: 0.6873 - val_auc: 0.9584 - lr: 1.0000e-10\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7321 - auc: 0.9573\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.7321 - auc: 0.9573 - val_loss: 0.6692 - val_auc: 0.9596 - lr: 1.0000e-10\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6353 - auc: 0.9638 - val_loss: 0.6522 - val_auc: 0.9603 - lr: 1.0000e-11\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6764 - auc: 0.9574 - val_loss: 0.6365 - val_auc: 0.9611 - lr: 1.0000e-11\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7688 - auc: 0.9549\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.7688 - auc: 0.9549 - val_loss: 0.6220 - val_auc: 0.9623 - lr: 1.0000e-11\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.7683 - auc: 0.9527 - val_loss: 0.6087 - val_auc: 0.9628 - lr: 1.0000e-12\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.8180 - auc: 0.9507 - val_loss: 0.5965 - val_auc: 0.9634 - lr: 1.0000e-12\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6858 - auc: 0.9601\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6858 - auc: 0.9601 - val_loss: 0.5854 - val_auc: 0.9633 - lr: 1.0000e-12\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.7016 - auc: 0.9562 - val_loss: 0.5753 - val_auc: 0.9637 - lr: 1.0000e-13\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6563 - auc: 0.9651 - val_loss: 0.5664 - val_auc: 0.9641 - lr: 1.0000e-13\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7957 - auc: 0.9503\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.7957 - auc: 0.9503 - val_loss: 0.5584 - val_auc: 0.9638 - lr: 1.0000e-13\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.5270 - auc: 0.9694 - val_loss: 0.5514 - val_auc: 0.9642 - lr: 1.0000e-14\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.7048 - auc: 0.9602 - val_loss: 0.5453 - val_auc: 0.9642 - lr: 1.0000e-14\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7362 - auc: 0.9586\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.7362 - auc: 0.9586 - val_loss: 0.5402 - val_auc: 0.9636 - lr: 1.0000e-14\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6429 - auc: 0.9613 - val_loss: 0.5358 - val_auc: 0.9642 - lr: 1.0000e-15\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.7971 - auc: 0.9496 - val_loss: 0.5322 - val_auc: 0.9641 - lr: 1.0000e-15\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6274 - auc: 0.9634\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6274 - auc: 0.9634 - val_loss: 0.5294 - val_auc: 0.9640 - lr: 1.0000e-15\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6790 - auc: 0.9590 - val_loss: 0.5272 - val_auc: 0.9638 - lr: 1.0000e-16\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6957 - auc: 0.9580 - val_loss: 0.5258 - val_auc: 0.9640 - lr: 1.0000e-16\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7749 - auc: 0.9556Restoring model weights from the end of the best epoch: 29.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.7749 - auc: 0.9556 - val_loss: 0.5249 - val_auc: 0.9642 - lr: 1.0000e-16\n",
      "Epoch 34: early stopping\n",
      "\t\t\u001B[94mModel trained:\u001B[0m\n",
      "\t\t\u001B[1mEvaluating...\u001B[0m\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.3857 - auc: 0.9861\n",
      "\t\t\u001B[1mTrain AUC:\u001B[0m 0.986055314540863\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5358 - auc: 0.9642\n",
      "\t\t\u001B[1mValidation AUC:\u001B[0m 0.9642444849014282\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.6342 - auc: 0.9451\n",
      "\t\t\u001B[1mTest AUC:\u001B[0m 0.9450678825378418\n",
      "\t\u001B[94mPseudo-labeling...\u001B[0m\n",
      "\u001B[94mPseudo-labeling results\u001B[0m\n",
      "Pseudo-labels: 28469\n",
      "Pseudo-labels distribution: [  767  4848 22854]\n",
      "\u001B[94mUndersampling results\u001B[0m\n",
      "Pseudo-labels: 2301\n",
      "Pseudo-labels distribution: [767 767 767]\n",
      "\u001B[94mSplitting pseudo-labeled images into 2D slices...\u001B[0m\n",
      "[==================================================] 100.00%\n",
      "\u001B[92mSplitting completed\u001B[0m\n",
      "\t\u001B[1mTotal instances:\u001B[0m 9392\n",
      "\u001B[92mIteration:\u001B[0m 2\n",
      "\t\u001B[94mPre-training...\u001B[0m\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 13:26:08.803886: W tensorflow/core/framework/op_kernel.cc:1733] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n",
      "    x = [self.__get_image(idx) for idx in batch_x]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n",
      "    x = [self.__get_image(idx) for idx in batch_x]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n",
      "    img = io.imread(idx)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n",
      "    return tifffile_imread(fname, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n",
      "    with TiffFile(\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n",
      "    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n",
      "    self.open()\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n",
      "    self._fh = open(\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert/data_2/_26]]\n  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2479]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSSL\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43munlabeled_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/cellular_division_models/vgg16_semi.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/semi_supervised.py:283\u001B[0m, in \u001B[0;36msemi_supervised_learning\u001B[0;34m(model, train, val, test, unlabeled, max_iter, batch_size, verbose)\u001B[0m\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m.\u001B[39mOKBLUE\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mPre-training...\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m.\u001B[39mENDC\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    282\u001B[0m \u001B[38;5;66;03m# Pre-train the model with the labeled data\u001B[39;00m\n\u001B[0;32m--> 283\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mpre_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    284\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mevaluate(val, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# Early stopping and saving the model\u001B[39;00m\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/semi_supervised.py:69\u001B[0m, in \u001B[0;36mpre_train\u001B[0;34m(model, train, val, batch_size, verbose)\u001B[0m\n\u001B[1;32m     66\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m train\n\u001B[1;32m     67\u001B[0m val_generator \u001B[38;5;241m=\u001B[39m val\n\u001B[0;32m---> 69\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/nets/transfer_learning.py:125\u001B[0m, in \u001B[0;36mCNN.fit\u001B[0;34m(self, train_gen, val_gen, epochs, batch_size, save, verbose)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save:\n\u001B[1;32m    116\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    117\u001B[0m         ModelCheckpoint(\n\u001B[1;32m    118\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/cellular_division_models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m         )\n\u001B[1;32m    123\u001B[0m     )\n\u001B[0;32m--> 125\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\n\u001B[1;32m    132\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;66;03m# self.model.summary()\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     acc \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauc\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mUnknownError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert/data_2/_26]]\n  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0402_E2_45799_1.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2479]"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.model.evaluate(test_generator)",
   "id": "66c309c011581255",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred = model.model.predict(test_generator).round().astype(int)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        test_generator.img_labels, [test_generator.oh2class(p) for p in pred], \n",
    "        target_names=test_generator.CLASS_NAMES,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ],
   "id": "51f9244aff993af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cf_matrix = confusion_matrix(\n",
    "   test_generator.img_labels, [test_generator.oh2class(p) for p in pred]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "vis.plot_confusion_matrix(cf_matrix)"
   ],
   "id": "3afeb6e8548cffd6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
