{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-12T15:59:59.082765Z",
     "start_time": "2024-08-12T15:59:56.081985Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cell_division.nets.transfer_learning import CNN\n",
    "from auxiliary.data.dataset_cell import CellDataset\n",
    "from auxiliary.data.dataset_unlabeled import UnlabeledDataset\n",
    "from auxiliary import values as v\n",
    "from auxiliary.utils.colors import bcolors as c\n",
    "from auxiliary.utils import visualizer as vis\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from cell_division.nets.custom_layers import (\n",
    "    w_cel_loss, \n",
    "    focal_loss,\n",
    "    ExtendedLSEPooling,\n",
    "    extended_w_cel_loss,\n",
    "    LSEPooling\n",
    ")\n",
    "\n",
    "from cell_division.nets.cam import GradCAM, overlay_heatmap, CAM, GradCAMpp\n",
    "from cell_division.semi_supervised import semi_supervised_learning as SSL\n",
    "\n",
    "# GPU config\n",
    "from auxiliary.utils.timer import LoadingBar\n",
    "from auxiliary.gpu.gpu_tf import (\n",
    "    increase_gpu_memory, \n",
    "    set_gpu_allocator, \n",
    "    clear_session\n",
    ")\n",
    "\n",
    "increase_gpu_memory()\n",
    "set_gpu_allocator()"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set memory growth on device when virtual devices configured",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 41\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauxiliary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtimer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoadingBar\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauxiliary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgpu\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgpu_tf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     36\u001B[0m     increase_gpu_memory, \n\u001B[1;32m     37\u001B[0m     set_gpu_allocator, \n\u001B[1;32m     38\u001B[0m     clear_session\n\u001B[1;32m     39\u001B[0m )\n\u001B[0;32m---> 41\u001B[0m \u001B[43mincrease_gpu_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m set_gpu_allocator()\n",
      "File \u001B[0;32m~/ht_morphogenesis/auxiliary/gpu/gpu_tf.py:15\u001B[0m, in \u001B[0;36mincrease_gpu_memory\u001B[0;34m(limit)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m gpu \u001B[38;5;129;01min\u001B[39;00m gpus:\n\u001B[0;32m---> 15\u001B[0m         \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_memory_growth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgpu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m         tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mset_virtual_device_configuration(\n\u001B[1;32m     17\u001B[0m             gpu,\n\u001B[1;32m     18\u001B[0m             [tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mVirtualDeviceConfiguration(memory_limit\u001B[38;5;241m=\u001B[39mlimit)]\n\u001B[1;32m     19\u001B[0m         )\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/config.py:713\u001B[0m, in \u001B[0;36mset_memory_growth\u001B[0;34m(device, enable)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.experimental.set_memory_growth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_memory_growth\u001B[39m(device, enable):\n\u001B[1;32m    690\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001B[39;00m\n\u001B[1;32m    691\u001B[0m \n\u001B[1;32m    692\u001B[0m \u001B[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001B[39;00m\n\u001B[1;32m    712\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 713\u001B[0m   \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_memory_growth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1577\u001B[0m, in \u001B[0;36mContext.set_memory_growth\u001B[0;34m(self, dev, enable)\u001B[0m\n\u001B[1;32m   1574\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized device: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mrepr\u001B[39m(dev))\n\u001B[1;32m   1576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_virtual_device_map:\n\u001B[0;32m-> 1577\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1578\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot set memory growth on device when virtual devices configured\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev\u001B[38;5;241m.\u001B[39mdevice_type \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1581\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot set memory growth on non-GPU devices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot set memory growth on device when virtual devices configured"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:59:59.614163Z",
     "start_time": "2024-08-12T15:59:59.609678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = v.data_path + 'CellDivision/images_nuclei/'\n",
    "img_dir_unlabeled = v.data_path + 'CellDivision/images_unlabeled/'\n",
    "\n",
    "label_train_dir = v.data_path + 'CellDivision/undersampled/train.csv'\n",
    "label_test_dir = v.data_path + 'CellDivision/undersampled/test.csv'\n",
    "label_val_dir = v.data_path + 'CellDivision/undersampled/val.csv'\n",
    "\n",
    "INPUT_SHAPE = (100, 100, 3)\n",
    "BATCH_SIZE = 64"
   ],
   "id": "a1afd82f2525feb7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T16:00:02.561602Z",
     "start_time": "2024-08-12T15:59:59.865019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_train_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "val_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_val_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "test_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_test_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "unlabeled_generator = UnlabeledDataset(\n",
    "    img_dir_unlabeled,\n",
    "    batch_size=1,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")"
   ],
   "id": "64e98694d41986fe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T16:00:03.221743Z",
     "start_time": "2024-08-12T16:00:02.563549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    base=tf.keras.applications.VGG16,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    n_classes=3\n",
    ")\n",
    "model.build_top(activation='softmax', b_type='CAM', pooling=ExtendedLSEPooling)\n",
    "model.compile(\n",
    "    lr=.001,\n",
    "    loss=extended_w_cel_loss()\n",
    ")"
   ],
   "id": "3747c34497d9ef9e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T18:20:29.371797Z",
     "start_time": "2024-08-12T16:02:36.595271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SSL(\n",
    "    model, \n",
    "    train_generator, val_generator, test_generator,\n",
    "    unlabeled_generator,\n",
    "    max_iter=10,\n",
    "    verbose=1\n",
    ")\n",
    "model.model.save('../models/cellular_division_models/vgg16_semi.h5')"
   ],
   "id": "97d72a54693578ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mIteration:\u001B[0m 1\n",
      "\t\u001B[94mPre-training...\u001B[0m\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5844 - auc: 0.9652 - val_loss: 1.1112 - val_auc: 0.8443 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6404 - auc: 0.9640 - val_loss: 1.1134 - val_auc: 0.8300 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7435 - auc: 0.9549 - val_loss: 1.0475 - val_auc: 0.8864 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.4683 - auc: 0.9734 - val_loss: 1.0142 - val_auc: 0.8976 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5539 - auc: 0.9721\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5539 - auc: 0.9721 - val_loss: 1.0354 - val_auc: 0.8733 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5403 - auc: 0.9718 - val_loss: 0.9887 - val_auc: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5761 - auc: 0.9654 - val_loss: 0.9509 - val_auc: 0.9252 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6098 - auc: 0.9629\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6098 - auc: 0.9629 - val_loss: 0.9227 - val_auc: 0.9336 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.5282 - auc: 0.9699 - val_loss: 0.8984 - val_auc: 0.9393 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.5431 - auc: 0.9737 - val_loss: 0.8745 - val_auc: 0.9434 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7133 - auc: 0.9607\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7133 - auc: 0.9607 - val_loss: 0.8505 - val_auc: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5262 - auc: 0.9711 - val_loss: 0.8261 - val_auc: 0.9504 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.4717 - auc: 0.9777 - val_loss: 0.8024 - val_auc: 0.9535 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5984 - auc: 0.9670\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.5984 - auc: 0.9670 - val_loss: 0.7794 - val_auc: 0.9562 - lr: 1.0000e-06\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.4655 - auc: 0.9743 - val_loss: 0.7573 - val_auc: 0.9576 - lr: 1.0000e-07\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.4071 - auc: 0.9792 - val_loss: 0.7363 - val_auc: 0.9595 - lr: 1.0000e-07\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5914 - auc: 0.9654\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.5914 - auc: 0.9654 - val_loss: 0.7164 - val_auc: 0.9601 - lr: 1.0000e-07\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.5076 - auc: 0.9760 - val_loss: 0.6977 - val_auc: 0.9613 - lr: 1.0000e-08\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6631 - auc: 0.9625 - val_loss: 0.6802 - val_auc: 0.9625 - lr: 1.0000e-08\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6086 - auc: 0.9635\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6086 - auc: 0.9635 - val_loss: 0.6640 - val_auc: 0.9631 - lr: 1.0000e-08\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.4211 - auc: 0.9783 - val_loss: 0.6489 - val_auc: 0.9633 - lr: 1.0000e-09\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6162 - auc: 0.9654 - val_loss: 0.6351 - val_auc: 0.9634 - lr: 1.0000e-09\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5613 - auc: 0.9694\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5613 - auc: 0.9694 - val_loss: 0.6225 - val_auc: 0.9636 - lr: 1.0000e-09\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.5588 - auc: 0.9711 - val_loss: 0.6110 - val_auc: 0.9636 - lr: 1.0000e-10\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.6599 - auc: 0.9639 - val_loss: 0.6006 - val_auc: 0.9636 - lr: 1.0000e-10\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6005 - auc: 0.9654\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.6005 - auc: 0.9654 - val_loss: 0.5913 - val_auc: 0.9636 - lr: 1.0000e-10\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.4709 - auc: 0.9760 - val_loss: 0.5830 - val_auc: 0.9637 - lr: 1.0000e-11\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5102 - auc: 0.9745 - val_loss: 0.5757 - val_auc: 0.9633 - lr: 1.0000e-11\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5293 - auc: 0.9687\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.5293 - auc: 0.9687 - val_loss: 0.5693 - val_auc: 0.9633 - lr: 1.0000e-11\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.3977 - auc: 0.9797 - val_loss: 0.5637 - val_auc: 0.9626 - lr: 1.0000e-12\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5612 - auc: 0.9710 - val_loss: 0.5589 - val_auc: 0.9629 - lr: 1.0000e-12\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5395 - auc: 0.9730Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.5395 - auc: 0.9730 - val_loss: 0.5550 - val_auc: 0.9627 - lr: 1.0000e-12\n",
      "Epoch 32: early stopping\n",
      "\t\t\u001B[94mModel trained:\u001B[0m\n",
      "\t\t\u001B[1mEvaluating...\u001B[0m\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4156 - auc: 0.9925\n",
      "\t\t\u001B[1mTrain AUC:\u001B[0m 0.9924577474594116\n",
      "2/2 [==============================] - 2s 734ms/step - loss: 0.5830 - auc: 0.9637\n",
      "\t\t\u001B[1mValidation AUC:\u001B[0m 0.9636918306350708\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.6735 - auc: 0.9429\n",
      "\t\t\u001B[1mTest AUC:\u001B[0m 0.9429289102554321\n",
      "\t\u001B[94mPseudo-labeling...\u001B[0m\n",
      "\u001B[94mPseudo-labeling results\u001B[0m\n",
      "Pseudo-labels: 30302\n",
      "Pseudo-labels distribution: [   64  3397 26841]\n",
      "\u001B[94mUndersampling results\u001B[0m\n",
      "Pseudo-labels: 192\n",
      "Pseudo-labels distribution: [64 64 64]\n",
      "\u001B[92mIteration:\u001B[0m 2\n",
      "\t\u001B[94mPre-training...\u001B[0m\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 20:20:29.321066: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: Can't convert non-rectangular Python sequence to Tensor.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 99, in __getitem__\n",
      "    return tf.convert_to_tensor(x), tf.convert_to_tensor(y)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "\n",
      "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: Can't convert non-rectangular Python sequence to Tensor.\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 99, in __getitem__\n    return tf.convert_to_tensor(x), tf.convert_to_tensor(y)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Can't convert non-rectangular Python sequence to Tensor.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert/data_0/_22]]\n  (1) INVALID_ARGUMENT:  ValueError: Can't convert non-rectangular Python sequence to Tensor.\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 99, in __getitem__\n    return tf.convert_to_tensor(x), tf.convert_to_tensor(y)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Can't convert non-rectangular Python sequence to Tensor.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2479]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSSL\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43munlabeled_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/cellular_division_models/vgg16_semi.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/semi_supervised.py:225\u001B[0m, in \u001B[0;36msemi_supervised_learning\u001B[0;34m(model, train, val, test, unlabeled, max_iter, batch_size, verbose)\u001B[0m\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m.\u001B[39mOKBLUE\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mPre-training...\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m.\u001B[39mENDC\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    224\u001B[0m \u001B[38;5;66;03m# Pre-train the model with the labeled data\u001B[39;00m\n\u001B[0;32m--> 225\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mpre_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mevaluate(val, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/semi_supervised.py:68\u001B[0m, in \u001B[0;36mpre_train\u001B[0;34m(model, train, val, batch_size, verbose)\u001B[0m\n\u001B[1;32m     65\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m train\n\u001B[1;32m     66\u001B[0m val_generator \u001B[38;5;241m=\u001B[39m val\n\u001B[0;32m---> 68\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/nets/transfer_learning.py:125\u001B[0m, in \u001B[0;36mCNN.fit\u001B[0;34m(self, train_gen, val_gen, epochs, batch_size, save, verbose)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save:\n\u001B[1;32m    116\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    117\u001B[0m         ModelCheckpoint(\n\u001B[1;32m    118\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/cellular_division_models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m         )\n\u001B[1;32m    123\u001B[0m     )\n\u001B[0;32m--> 125\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\n\u001B[1;32m    132\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;66;03m# self.model.summary()\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     acc \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauc\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ValueError: Can't convert non-rectangular Python sequence to Tensor.\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 99, in __getitem__\n    return tf.convert_to_tensor(x), tf.convert_to_tensor(y)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Can't convert non-rectangular Python sequence to Tensor.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert/data_0/_22]]\n  (1) INVALID_ARGUMENT:  ValueError: Can't convert non-rectangular Python sequence to Tensor.\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 99, in __getitem__\n    return tf.convert_to_tensor(x), tf.convert_to_tensor(y)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Can't convert non-rectangular Python sequence to Tensor.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2479]"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.model.evaluate(test_generator)",
   "id": "66c309c011581255",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred = model.model.predict(test_generator).round().astype(int)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        test_generator.img_labels, [test_generator.oh2class(p) for p in pred], \n",
    "        target_names=test_generator.CLASS_NAMES,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ],
   "id": "51f9244aff993af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cf_matrix = confusion_matrix(\n",
    "   test_generator.img_labels, [test_generator.oh2class(p) for p in pred]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "vis.plot_confusion_matrix(cf_matrix)"
   ],
   "id": "3afeb6e8548cffd6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
