{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-12T13:11:34.649837Z",
     "start_time": "2024-08-12T13:11:31.741568Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cell_division.nets.transfer_learning import CNN\n",
    "from auxiliary.data.dataset_cell import CellDataset\n",
    "from auxiliary.data.dataset_unlabeled import UnlabeledDataset\n",
    "from auxiliary import values as v\n",
    "from auxiliary.utils.colors import bcolors as c\n",
    "from auxiliary.utils import visualizer as vis\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from cell_division.nets.custom_layers import (\n",
    "    w_cel_loss, \n",
    "    focal_loss,\n",
    "    ExtendedLSEPooling,\n",
    "    extended_w_cel_loss,\n",
    "    LSEPooling\n",
    ")\n",
    "\n",
    "from cell_division.nets.cam import GradCAM, overlay_heatmap, CAM, GradCAMpp\n",
    "from cell_division.semi_supervised import semi_supervised_learning as SSL\n",
    "\n",
    "# GPU config\n",
    "from auxiliary.utils.timer import LoadingBar\n",
    "from auxiliary.gpu.gpu_tf import (\n",
    "    increase_gpu_memory, \n",
    "    set_gpu_allocator, \n",
    "    clear_session\n",
    ")\n",
    "\n",
    "increase_gpu_memory()\n",
    "set_gpu_allocator()"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set memory growth on device when virtual devices configured",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 41\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauxiliary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtimer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoadingBar\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauxiliary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgpu\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgpu_tf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     36\u001B[0m     increase_gpu_memory, \n\u001B[1;32m     37\u001B[0m     set_gpu_allocator, \n\u001B[1;32m     38\u001B[0m     clear_session\n\u001B[1;32m     39\u001B[0m )\n\u001B[0;32m---> 41\u001B[0m \u001B[43mincrease_gpu_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m set_gpu_allocator()\n",
      "File \u001B[0;32m~/ht_morphogenesis/auxiliary/gpu/gpu_tf.py:15\u001B[0m, in \u001B[0;36mincrease_gpu_memory\u001B[0;34m(limit)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m gpu \u001B[38;5;129;01min\u001B[39;00m gpus:\n\u001B[0;32m---> 15\u001B[0m         \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_memory_growth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgpu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m         tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mset_virtual_device_configuration(\n\u001B[1;32m     17\u001B[0m             gpu,\n\u001B[1;32m     18\u001B[0m             [tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mVirtualDeviceConfiguration(memory_limit\u001B[38;5;241m=\u001B[39mlimit)]\n\u001B[1;32m     19\u001B[0m         )\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/framework/config.py:713\u001B[0m, in \u001B[0;36mset_memory_growth\u001B[0;34m(device, enable)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.experimental.set_memory_growth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_memory_growth\u001B[39m(device, enable):\n\u001B[1;32m    690\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001B[39;00m\n\u001B[1;32m    691\u001B[0m \n\u001B[1;32m    692\u001B[0m \u001B[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001B[39;00m\n\u001B[1;32m    712\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 713\u001B[0m   \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_memory_growth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1577\u001B[0m, in \u001B[0;36mContext.set_memory_growth\u001B[0;34m(self, dev, enable)\u001B[0m\n\u001B[1;32m   1574\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized device: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mrepr\u001B[39m(dev))\n\u001B[1;32m   1576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_virtual_device_map:\n\u001B[0;32m-> 1577\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1578\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot set memory growth on device when virtual devices configured\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev\u001B[38;5;241m.\u001B[39mdevice_type \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1581\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot set memory growth on non-GPU devices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot set memory growth on device when virtual devices configured"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:11:35.405877Z",
     "start_time": "2024-08-12T13:11:35.402107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = v.data_path + 'CellDivision/images_nuclei/'\n",
    "img_dir_unlabeled = v.data_path + 'CellDivision/images_unlabeled/'\n",
    "\n",
    "label_train_dir = v.data_path + 'CellDivision/undersampled/train.csv'\n",
    "label_test_dir = v.data_path + 'CellDivision/undersampled/test.csv'\n",
    "label_val_dir = v.data_path + 'CellDivision/undersampled/val.csv'\n",
    "\n",
    "INPUT_SHAPE = (100, 100, 3)\n",
    "BATCH_SIZE = 64"
   ],
   "id": "a1afd82f2525feb7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:11:38.204191Z",
     "start_time": "2024-08-12T13:11:36.439839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_train_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "val_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_val_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "test_generator = CellDataset(\n",
    "    img_dir, \n",
    "    label_test_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")\n",
    "\n",
    "unlabeled_generator = UnlabeledDataset(\n",
    "    img_dir_unlabeled,\n",
    "    batch_size=1,\n",
    "    resize=INPUT_SHAPE[:2]\n",
    ")"
   ],
   "id": "64e98694d41986fe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:11:39.023191Z",
     "start_time": "2024-08-12T13:11:38.205702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNN(\n",
    "    base=tf.keras.applications.VGG16,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    n_classes=3\n",
    ")\n",
    "model.build_top(activation='softmax', b_type='CAM', pooling=ExtendedLSEPooling)\n",
    "model.compile(\n",
    "    lr=.001,\n",
    "    loss=extended_w_cel_loss()\n",
    ")"
   ],
   "id": "3747c34497d9ef9e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:34:31.306908Z",
     "start_time": "2024-08-12T13:15:36.062513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SSL(\n",
    "    model, \n",
    "    train_generator, val_generator, test_generator,\n",
    "    unlabeled_generator,\n",
    "    max_iter=10,\n",
    "    verbose=1\n",
    ")\n",
    "model.model.save('../models/cellular_division_models/vgg16_semi.h5')"
   ],
   "id": "97d72a54693578ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mIteration:\u001B[0m 1\n",
      "\t\u001B[94mPre-training...\u001B[0m\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.9429 - auc: 0.9444 - val_loss: 1.1420 - val_auc: 0.9070 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.9015 - auc: 0.9455 - val_loss: 1.1242 - val_auc: 0.9108 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.8155 - auc: 0.9485 - val_loss: 1.1061 - val_auc: 0.9143 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8770 - auc: 0.9460\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.8770 - auc: 0.9460 - val_loss: 1.0870 - val_auc: 0.9182 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7498 - auc: 0.9590 - val_loss: 1.0663 - val_auc: 0.9220 - lr: 1.0000e-06\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7520 - auc: 0.9542 - val_loss: 1.0450 - val_auc: 0.9262 - lr: 1.0000e-06\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8366 - auc: 0.9467\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8366 - auc: 0.9467 - val_loss: 1.0233 - val_auc: 0.9296 - lr: 1.0000e-06\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7209 - auc: 0.9581 - val_loss: 1.0010 - val_auc: 0.9331 - lr: 1.0000e-07\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.9334 - auc: 0.9467 - val_loss: 0.9785 - val_auc: 0.9358 - lr: 1.0000e-07\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7326 - auc: 0.9578\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7326 - auc: 0.9578 - val_loss: 0.9558 - val_auc: 0.9372 - lr: 1.0000e-07\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8389 - auc: 0.9516 - val_loss: 0.9330 - val_auc: 0.9406 - lr: 1.0000e-08\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7479 - auc: 0.9585 - val_loss: 0.9102 - val_auc: 0.9426 - lr: 1.0000e-08\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7301 - auc: 0.9558\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7301 - auc: 0.9558 - val_loss: 0.8877 - val_auc: 0.9443 - lr: 1.0000e-08\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.7910 - auc: 0.9514 - val_loss: 0.8655 - val_auc: 0.9454 - lr: 1.0000e-09\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7055 - auc: 0.9588 - val_loss: 0.8437 - val_auc: 0.9468 - lr: 1.0000e-09\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9330 - auc: 0.9452\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.9330 - auc: 0.9452 - val_loss: 0.8224 - val_auc: 0.9477 - lr: 1.0000e-09\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.9056 - auc: 0.9501 - val_loss: 0.8019 - val_auc: 0.9487 - lr: 1.0000e-10\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7560 - auc: 0.9581 - val_loss: 0.7821 - val_auc: 0.9497 - lr: 1.0000e-10\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7246 - auc: 0.9586\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7246 - auc: 0.9586 - val_loss: 0.7632 - val_auc: 0.9505 - lr: 1.0000e-10\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7333 - auc: 0.9595 - val_loss: 0.7452 - val_auc: 0.9511 - lr: 1.0000e-11\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7054 - auc: 0.9570 - val_loss: 0.7281 - val_auc: 0.9518 - lr: 1.0000e-11\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7946 - auc: 0.9559\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7946 - auc: 0.9559 - val_loss: 0.7121 - val_auc: 0.9520 - lr: 1.0000e-11\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8197 - auc: 0.9482 - val_loss: 0.6971 - val_auc: 0.9521 - lr: 1.0000e-12\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6900 - auc: 0.9624 - val_loss: 0.6831 - val_auc: 0.9524 - lr: 1.0000e-12\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7957 - auc: 0.9510\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7957 - auc: 0.9510 - val_loss: 0.6703 - val_auc: 0.9525 - lr: 1.0000e-12\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6678 - auc: 0.9628 - val_loss: 0.6585 - val_auc: 0.9522 - lr: 1.0000e-13\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.8685 - auc: 0.9486 - val_loss: 0.6477 - val_auc: 0.9522 - lr: 1.0000e-13\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.9791 - auc: 0.9419\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.9791 - auc: 0.9419 - val_loss: 0.6380 - val_auc: 0.9526 - lr: 1.0000e-13\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.8515 - auc: 0.9501 - val_loss: 0.6292 - val_auc: 0.9526 - lr: 1.0000e-14\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7669 - auc: 0.9533 - val_loss: 0.6215 - val_auc: 0.9531 - lr: 1.0000e-14\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8299 - auc: 0.9537\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8299 - auc: 0.9537 - val_loss: 0.6148 - val_auc: 0.9533 - lr: 1.0000e-14\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7931 - auc: 0.9560 - val_loss: 0.6090 - val_auc: 0.9536 - lr: 1.0000e-15\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8544 - auc: 0.9532 - val_loss: 0.6041 - val_auc: 0.9533 - lr: 1.0000e-15\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8670 - auc: 0.9495\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8670 - auc: 0.9495 - val_loss: 0.6001 - val_auc: 0.9535 - lr: 1.0000e-15\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7880 - auc: 0.9596 - val_loss: 0.5969 - val_auc: 0.9532 - lr: 1.0000e-16\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.7416 - auc: 0.9536 - val_loss: 0.5946 - val_auc: 0.9539 - lr: 1.0000e-16\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7996 - auc: 0.9512\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.7996 - auc: 0.9512 - val_loss: 0.5930 - val_auc: 0.9535 - lr: 1.0000e-16\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.8769 - auc: 0.9473 - val_loss: 0.5921 - val_auc: 0.9534 - lr: 1.0000e-17\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6964 - auc: 0.9554 - val_loss: 0.5919 - val_auc: 0.9537 - lr: 1.0000e-17\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8626 - auc: 0.9488\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8626 - auc: 0.9488 - val_loss: 0.5924 - val_auc: 0.9538 - lr: 1.0000e-17\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.8757 - auc: 0.9477Restoring model weights from the end of the best epoch: 36.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.8757 - auc: 0.9477 - val_loss: 0.5935 - val_auc: 0.9535 - lr: 1.0000e-18\n",
      "Epoch 41: early stopping\n",
      "\t\t\u001B[94mModel trained:\u001B[0m\n",
      "\t\t\u001B[1mEvaluating...\u001B[0m\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4147 - auc: 0.9825\n",
      "\t\t\u001B[1mTrain AUC:\u001B[0m 0.9825307726860046\n",
      "2/2 [==============================] - 2s 730ms/step - loss: 0.5946 - auc: 0.9539\n",
      "\t\t\u001B[1mValidation AUC:\u001B[0m 0.9538638591766357\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6351 - auc: 0.9459\n",
      "\t\t\u001B[1mTest AUC:\u001B[0m 0.9458738565444946\n",
      "\t\u001B[94mPseudo-labeling...\u001B[0m\n",
      "\u001B[94mPseudo-labeling results\u001B[0m\n",
      "Pseudo-labels: 30075\n",
      "Pseudo-labels distribution: [  313  1259 28503]\n",
      "\u001B[94mUndersampling results\u001B[0m\n",
      "Pseudo-labels: 939\n",
      "Pseudo-labels distribution: [313 313 313]\n",
      "\u001B[92mIteration:\u001B[0m 2\n",
      "\t\u001B[94mPre-training...\u001B[0m\n",
      "Epoch 1/100\n",
      " 1/21 [>.............................] - ETA: 27s - loss: 0.8092 - auc: 0.9513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 17:34:31.239045: W tensorflow/core/framework/op_kernel.cc:1733] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n",
      "    x = [self.__get_image(idx) for idx in batch_x]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n",
      "    x = [self.__get_image(idx) for idx in batch_x]\n",
      "\n",
      "  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n",
      "    img = io.imread(idx)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n",
      "    return tifffile_imread(fname, **kwargs)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n",
      "    with TiffFile(\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n",
      "    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n",
      "    self.open()\n",
      "\n",
      "  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n",
      "    self._fh = open(\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2479]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSSL\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43munlabeled_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/cellular_division_models/vgg16_semi.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/semi_supervised.py:221\u001B[0m, in \u001B[0;36msemi_supervised_learning\u001B[0;34m(model, train, val, test, unlabeled, max_iter, batch_size, verbose)\u001B[0m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m.\u001B[39mOKBLUE\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mPre-training...\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m.\u001B[39mENDC\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    220\u001B[0m \u001B[38;5;66;03m# Pre-train the model with the labeled data\u001B[39;00m\n\u001B[0;32m--> 221\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mpre_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    222\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mevaluate(val, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/semi_supervised.py:68\u001B[0m, in \u001B[0;36mpre_train\u001B[0;34m(model, train, val, batch_size, verbose)\u001B[0m\n\u001B[1;32m     65\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m train\n\u001B[1;32m     66\u001B[0m val_generator \u001B[38;5;241m=\u001B[39m val\n\u001B[0;32m---> 68\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/ht_morphogenesis/cell_division/nets/transfer_learning.py:125\u001B[0m, in \u001B[0;36mCNN.fit\u001B[0;34m(self, train_gen, val_gen, epochs, batch_size, save, verbose)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save:\n\u001B[1;32m    116\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    117\u001B[0m         ModelCheckpoint(\n\u001B[1;32m    118\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/cellular_division_models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m         )\n\u001B[1;32m    123\u001B[0m     )\n\u001B[0;32m--> 125\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\n\u001B[1;32m    132\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;66;03m# self.model.summary()\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     acc \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauc\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mUnknownError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\nTraceback (most recent call last):\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in __getitem__\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 96, in <listcomp>\n    x = [self.__get_image(idx) for idx in batch_x]\n\n  File \"/home/imarcoss/ht_morphogenesis/auxiliary/data/dataset_cell.py\", line 78, in __get_image\n    img = io.imread(idx)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_io.py\", line 60, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 217, in call_plugin\n    return func(*args, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1248, in imread\n    with TiffFile(\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 4259, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14644, in __init__\n    self.open()\n\n  File \"/home/imarcoss/mambaforge/envs/py310ml/lib/python3.10/site-packages/tifffile/tifffile.py\", line 14663, in open\n    self._fh = open(\n\nFileNotFoundError: [Errno 2] No such file or directory: '/run/user/1003/gvfs/smb-share:server=tierra.cnic.es,share=sc/LAB_MT/LAB/Ignacio/CellDivision/images_unlabeled/0518_E3_23257.tif.tif'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_2479]"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.model.evaluate(test_generator)",
   "id": "66c309c011581255",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred = model.model.predict(test_generator).round().astype(int)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        test_generator.img_labels, [test_generator.oh2class(p) for p in pred], \n",
    "        target_names=test_generator.CLASS_NAMES,\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ],
   "id": "51f9244aff993af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cf_matrix = confusion_matrix(\n",
    "   test_generator.img_labels, [test_generator.oh2class(p) for p in pred]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "vis.plot_confusion_matrix(cf_matrix)"
   ],
   "id": "3afeb6e8548cffd6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
