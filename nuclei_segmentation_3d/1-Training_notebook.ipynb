{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "116abf37",
   "metadata": {},
   "source": [
    "# StarDist 3D - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c13a7",
   "metadata": {},
   "source": [
    "Let's check that tensorflow-GPU is working ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9047164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.test.is_gpu_available( cuda_only=False, min_cuda_compute_capability=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620df218",
   "metadata": {},
   "source": [
    "Code below is simply modified from [StarDist example](https://github.com/stardist/stardist/blob/master/examples/3D/2_training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist import Rays_GoldenSpiral\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config3D, StarDist3D, StarDistData3D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f63f6",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your images should be in two different folders :\n",
    "\n",
    "#main_dir\n",
    "#|_main_image_dir\n",
    "#    |_images\n",
    "#        |_img1.tif\n",
    "#        |_...\n",
    "#    |_masks\n",
    "#        |_img1.tif\n",
    "#        |_...\n",
    "#|_models\n",
    "#1-Training_notebook\n",
    "#2-QC_notebook\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55000b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction = 0.25\n",
    "main_image_dir = \"crops_BIOP_v1\"\n",
    "rdmSeed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee001e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob(main_image_dir+'/images/*.tif'))\n",
    "Y = sorted(glob(main_image_dir+'/masks/*.tif'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n",
    "\n",
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 3 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac396906",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_norm = (0,1,2)   # normalize channels independently\n",
    "# axis_norm = (0,1,2,3) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 3 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c61623",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(rdmSeed)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(val_fraction * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74d355",
   "metadata": {},
   "source": [
    "here we just resave the images use for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1264de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "import os\n",
    "\n",
    "val_dir = 'val/'\n",
    "X_val_dir = val_dir+'images/'\n",
    "Y_val_dir = val_dir+'masks/'\n",
    "\n",
    "if ( not os.path.isdir(val_dir) ): os.mkdir(val_dir)\n",
    "if ( not os.path.isdir(X_val_dir) ): os.mkdir(X_val_dir)\n",
    "if ( not os.path.isdir(Y_val_dir) ): os.mkdir(Y_val_dir)\n",
    "\n",
    "cnt = 1 \n",
    "for img in X_val:\n",
    "    imsave(X_val_dir+str(cnt)+'.tif', img)\n",
    "    cnt+=1\n",
    "\n",
    "cnt = 1\n",
    "for img in Y_val:\n",
    "    imsave(Y_val_dir+str(cnt)+'.tif', img)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f172f",
   "metadata": {},
   "source": [
    "## Check anisotropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09160949",
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = calculate_extents(Y)\n",
    "anisotropy = tuple(np.max(extents) / extents)\n",
    "print('empirical anisotropy of labeled objects = %s' % str(anisotropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300466c",
   "metadata": {},
   "source": [
    "## Define Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 96\n",
    "\n",
    "anisotropy = (1.6,1,1)\n",
    "train_patch = (48,64,64)\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = True and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "#grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "grid = (1,1,1)\n",
    "# Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "model_name = \"n1_stardist_\"+str(n_rays)+\"_\"+str(anisotropy)+\"_\"+str(train_patch)+\"_\"+str(grid)\n",
    "\n",
    "conf = Config3D (\n",
    "    rays             = rays,\n",
    "    grid             = grid,\n",
    "    anisotropy       = anisotropy,\n",
    "    n_channel_in     = n_channel,\n",
    "    # adjust for your data below (make patch size as large as possible)\n",
    "    train_patch_size = train_patch,\n",
    "    train_batch_size = 1,\n",
    ")\n",
    "print(model_name)\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "    limit_gpu_memory(0.9)\n",
    "    # alternatively, try this:\n",
    "    # limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist3D(conf, name=model_name, basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask, axis=None): \n",
    "    if axis is None:\n",
    "        axis = tuple(range(mask.ndim))\n",
    "    axis = tuple(axis)\n",
    "            \n",
    "    assert img.ndim>=mask.ndim\n",
    "    perm = tuple(np.random.permutation(axis))\n",
    "    transpose_axis = np.arange(mask.ndim)\n",
    "    for a, p in zip(axis, perm):\n",
    "        transpose_axis[a] = p\n",
    "    transpose_axis = tuple(transpose_axis)\n",
    "    img = img.transpose(transpose_axis + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(transpose_axis) \n",
    "    for ax in axis: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    # Note that we only use fliprots along axis=(1,2), i.e. the yx axis \n",
    "    # as 3D microscopy acquisitions are usually not axially symmetric\n",
    "    x, y = random_fliprot(x, y, axis=(1,2))\n",
    "    x = random_intensity_change(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce14089",
   "metadata": {},
   "source": [
    "## Finally we can start Training ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdda9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c821a",
   "metadata": {},
   "source": [
    "## and here we optimize thresholds and plot some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c420c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d07284",
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2551c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c79dc0",
   "metadata": {},
   "source": [
    "You can find your newly trained model in the models folder and open the [QC_notebook](2-QC_notebook.ipynb) to look to the metrics in more details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
